[{"title":"CNN模块设计","url":"/2024/02/26/CNN%E6%A8%A1%E5%9D%97%E8%AE%BE%E8%AE%A1/","content":"AlexNet(2012)\n分组卷积 \n操作：先将特征通道分组，再卷积操作限制在对应组内。\n优点：减少了浮点运算量和参数量。\n缺点：阻碍了通道之间的信息流，削弱了网络的表达能力。\nShuffleNet(2018)\n通道洗牌操作：用较小的代价实现了组卷积通道间的信息交互，精度提升。\nShuffleNetV2\n通道划分操作代替分组卷积\nMobileNet(2017)\n深度可分离卷积：将标准卷积拆分为深度卷积和点卷积，其中深度卷积为分组数等于通道数的组卷积。\nMobileNetV2(2018)\n倒置残差模块：由一个升维的点卷积、一个深度卷积、一个降维的点卷积以及残差连接组成.\nMobileNetV3(2019)\n倒置残差模块加入SE模块：引入了h-swish作为非线性激活函数，同时引入了网络搜索技术来进一步提高网络效率.\nEfficientNet(2020)\n基于 MobileNetV2模块使用网络搜索技术\nEfficientNetV2(2021)\n利用优化器的角度改进了MobileNetV3模块，并将其加入搜索空间\n原始卷积\n由图可以看到，卷积过程为：将filter与矩阵叠加，然后执行相应元素的相乘，将相乘的结果进行求和，得到输出图片的目标像素值（特征图），重复操作在所有位置上。\n卷积核的不同可以提取不同的特征\n代码实现：\nimport numpy as npdef numpy_conv2d(image, kernel, stride=1, padding=&#x27;same&#x27;):    # 输入和卷积核转为NumPy数组    image = np.array(image)    kernel = np.array(kernel)        # 处理多通道输入（RGB图像）    if len(image.shape) == 3:        return np.stack([numpy_conv2d(image[:,:,c], kernel) for c in range(image.shape[2])], axis=2)        # 添加padding    k_h, k_w = kernel.shape    if padding == &#x27;same&#x27;:        pad_h = (k_h - 1) // 2        pad_w = (k_w - 1) // 2        image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode=&#x27;constant&#x27;)        # 计算输出尺寸    out_h = (image.shape[0] - k_h) // stride + 1    out_w = (image.shape[1] - k_w) // stride + 1        # 初始化输出矩阵    output = np.zeros((out_h, out_w))        # 向量化计算    for i in range(out_h):        for j in range(out_w):            h_start = i * stride            w_start = j * stride            receptive_field = image[h_start:h_start+k_h, w_start:w_start+k_w]            output[i, j] = np.sum(receptive_field * kernel)    return output# 测试用例image = np.random.randn(224, 224)  # 模拟输入图像kernel = np.array([[1, 0, -1],      # Sobel水平边缘检测核                   [2, 0, -2],                   [1, 0, -1]])result = numpy_conv2d(image, kernel, padding=&#x27;same&#x27;)\n\n\n使用pytorch实现：\nimport torchimport torch.nn as nn# 定义标准卷积层standard_conv = nn.Conv2d(    in_channels=3,      # 输入通道数    out_channels=64,    # 输出通道数    kernel_size=3,      # 卷积核尺寸 (3x3)    stride=1,           # 步长    padding=1,          # 填充    bias=False          # 是否使用偏置项)# 输入数据 (Batch=4, Channels=3, Height=224, Width=224)x = torch.randn(4, 3, 224, 224)output = standard_conv(x)print(output.shape)  # 输出形状: [4, 64, 224, 224]\n\n分组卷积特性：参数量减少，是普通卷积的1&#x2F;group倍。用来降低参数量，就是速度会减慢。\n#分4组group_conv = nn.Conv2d(    in_channels=64,    out_channels=64,  # 输出通道数必须能被 groups 整除    kernel_size=3,    stride=1,    padding=1,    groups=4,          # 关键参数：分4组    bias=False)x = torch.randn(4, 64, 224, 224)output = group_conv(x)print(output.shape)  # 输出形状: [4, 64, 224, 224]\n\n\n\n深度可分离卷积class DepthwiseSeparableConv(nn.Module):    def __init__(self, in_channels, out_channels):        super().__init__()        # 深度卷积（每个输入通道单独卷积）        self.depthwise = nn.Conv2d(            in_channels,             in_channels,  # 输出通道数 = 输入通道数            kernel_size=3,            padding=1,            groups=in_channels,  # 关键：groups=输入通道数            bias=False        )        # 逐点卷积（1x1卷积组合通道信息）        self.pointwise = nn.Conv2d(            in_channels,            out_channels,            kernel_size=1,  # 1x1卷积核            bias=False        )        def forward(self, x):        x = self.depthwise(x)        x = self.pointwise(x)        return x# 使用示例ds_conv = DepthwiseSeparableConv(in_channels=64, out_channels=128)x = torch.randn(4, 64, 224, 224)output = ds_conv(x)print(output.shape)  # 输出形状: [4, 128, 224, 224]\n\n"},{"title":"FLANet","url":"/2024/11/11/FLANet/","content":"全称:Fully Attentional Network for Semantic Segmentation\n全注意力模块代码:\nclass FullyAttentionalBlock(nn.Module):    def __init__(self, plane, norm_layer=SyncBatchNorm):        super(FullyAttentionalBlock, self).__init__()        #用于在高度和宽度方向上编码特征的线性层        self.conv1 = nn.Linear(plane, plane)        self.conv2 = nn.Linear(plane, plane)                self.conv = nn.Sequential(nn.Conv2d(plane, plane, 3, stride=1, padding=1, bias=False),                                  norm_layer(plane),                                  nn.ReLU())        self.softmax = nn.Softmax(dim=-1)        self.gamma = nn.Parameter(torch.zeros(1))    def forward(self, x):        batch_size, _, height, width = x.size()        feat_h = x.permute(0, 3, 1, 2).contiguous().view(batch_size * width, -1, height)        feat_w = x.permute(0, 2, 1, 3).contiguous().view(batch_size * height, -1, width)        encode_h = self.conv1(F.avg_pool2d(x, [1, width]).view(batch_size, -1, height).permute(0, 2, 1).contiguous())        encode_w = self.conv2(F.avg_pool2d(x, [height, 1]).view(batch_size, -1, width).permute(0, 2, 1).contiguous())        energy_h = torch.matmul(feat_h, encode_h.repeat(width, 1, 1))#通过矩阵乘法计算高度方向的能量分数。        energy_w = torch.matmul(feat_w, encode_w.repeat(height, 1, 1))        full_relation_h = self.softmax(energy_h)  # [b*w, c, c]   获得高度方向的注意力权重        full_relation_w = self.softmax(energy_w)        full_aug_h = torch.bmm(full_relation_h, feat_h).view(batch_size, width, -1, height).permute(0, 2, 3, 1)#使用批量矩阵乘法 (torch.bmm) 将高度方向的注意力应用于 feat_h        full_aug_w = torch.bmm(full_relation_w, feat_w).view(batch_size, height, -1, width).permute(0, 2, 1, 3)        out = self.gamma * (full_aug_h + full_aug_w) + x         out = self.conv(out)        return out\n\nabstract在原来可以通过压缩空间维度或通过压缩通道的相似图来描述沿通道或空间维度的特征关系，但是这样会沿着其他维度压缩特征依赖性，就会导致注意力缺失，对小类别的结果较差或者大对象内分割不一致。\nIntroduction在FLANet中，将空间和通道注意力编码到在单个相似图中，同时保持高计算效率。\n\n空间NL可以增强细节的辨别力，而通道NL则有利于保持大对象内部的语义一致性空间NL可以增强细节的辨别力，而通道NL则有利于保持大对象内部的语义一致性。\n而且单纯把两个NL模块堆叠起来使用还是会出现注意力缺失的问题，注意力缺失问题会损害特征表示能力，并且不能通过简单地堆叠不同的NL块来解决。，但是FLA解决了这一问题。\nFLA基本思想:在计算通道注意力图时利用全局上下文信息来接收空间响应，从而能够在单个注意力单元中实现充分的注意力，并且具有较高的计算效率。具体来说，我们首先使每个空间位置能够从具有相同水平和垂直坐标的全局上下文中获取特征响应。其次，我们使用自注意力机制来捕获任意两个通道图之间的完全注意力相似性以及相关的空间位置,最后，通过整合所有通道图和相关全局线索之间的特征，使用生成的完全注意相似性来重新加权每个通道图。\nMethod\n为了避免增加额外的计算负担，我们尝试利用全局平均池化结果作为全局上下文先验，将空间交互引入通道NL机制。\n具体计算过程：\n给定输入特征图 Fin ∈ RC×H×W ，其中 C 是通道数，H 和 W 是输入张量的空间维度。首先，我们将 Fin 输入到底部的两个平行路径（即构建），每个路径都包含一个全局平均池化层，后面跟着一个线性层。在选择池化窗口的大小时，我们考虑了以下两个方面。首先，为了获得更丰富的全局上下文先验，我们选择在高度和宽度方向上使用不相等的全局池化大小而不是内核像3×3这样的窗口。其次，为了确保每个空间位置都与具有相同水平或垂直坐标的相应全局先验连接，即在计算通道关系时保持空间一致性，我们选择保留一维的长度持续的。因此，我们在这两个路径中分别采用大小为 H × 1 和 1 × W 的池化窗口。这给出 ˆ Qw ∈ RC×1×W 和 ˆ Qh ∈ RC×H×1。之后，我们重复 ^ Qw 和 ^ Qh 形成全局特征 Qw ∈ RC×H×W 和 Qh ∈ RC×H×W 。请注意，Qw和Qh分别表示水平和垂直方向上的全局先验，它们将用于实现相应维度上的空间交互。此外，我们沿 H 维度切割 Qw，从中我们可以生成一组大小为 RC×W 的 H 切片。同样，我们沿着W维度切割Qh。然后我们合并这两个组以形成最终的全局上下文 Q ∈ R(H+W )×C×S。剪切和合并操作如图3 所示。同时，我们沿 H 维度切割输入特征 Fin，产生一组大小为 RC×W 的 H 切片。同样，我们沿着 W 维度进行此操作。与 Q 的合并过程一样，这两组被整合形成特征 K ∈ R(H+W )×S×C 。以同样的方式，我们可以生成特征图V ∈ R(H+W )×C×S。\n贡献:\n发现非局部自注意力方法中存在注意力缺失问题，这会损害特征表示的完整性。 \n我们将自注意力机制重新表述为完全注意力方式，以生成密集且全面的特征依赖关系，从而有效且高效地解决注意力缺失问题.\n实验广泛。\n\n不足:极高的计算量限制了其实际应用.\n","tags":["论文阅读"]},{"title":"ModelCompression","url":"/2025/02/26/ModelCompression/","content":"模型压缩通用方法模型压缩是指将原本的大网络模型通过一些技术手段，压缩成为具有更好的实时性或参数量更小的模型。常见的模型压缩技术包括网络剪枝、神经架构搜索、知识蒸馏和量化。\n网络剪枝（network pruning）是指去掉网络模型中不必要的参数。网络剪枝的一般步骤是：训练一个大网络、评估每个参数的重要性、去掉不重要的参数以及微调去掉参数后的网络以恢复剪枝损失的部分精度。剪枝可以利用大模型本身容易训练到较高精度的优势，以最小的精度损失代价来获得更小的模型。\n\n如何确定要保留什么结构以及修剪哪些结构？\n\n1.可以修剪绝对值（或幅度）最小的权重。（属于非结构化剪枝，无法加速稀疏矩阵计算）\n2.根据过滤器的范数（L1或者L2）对过滤器进行排序（？）\n3.在要修剪的每组图层之后为每个特征图插入一个可学习的乘法参数，当参数减少到0时，有效修剪了负责这个通道的整套参数，这个参数的大小说明了所有参数的重要性。\n4.在小批量训练数据上累积梯度，并根据该梯度与每个参数的相应权重之间的乘积进行修剪。\n知识蒸馏（knowledge distillation）利用大型教师模型网络参数包含的知识监督小型学生模型，使其能够在一定程度上拟合大的教师模型的输出，从而提高学生模型的精度，以得到更高精度的紧凑小模型。\n量化（quantization）是指通过一定技术手段降低模型的数字精度以达到压缩模型、加快推理速度的效果，是模型部署常用的技术之一。\n接下来使用一个简单的CNN模型为例学习\n剪枝原理：\n剪枝基于权重的重要性进行，例中使用了L1范数作为重要性度量\n将不重要的权重设置为0，从而减少模型计算量\n剪枝后的模型需要微调来恢复性能\nimport torchimport torch.nn as nnimport torch.nn.utils.prune as pruneclass SimpleCNN(nn.Module):    def __init__(self):        super(SimpleCNN, self).__init__()        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)        self.fc1 = nn.Linear(32 * 8 * 8, 10)        self.relu = nn.ReLU()        self.pool = nn.MaxPool2d(2, 2)    def forward(self, x):        x = self.pool(self.relu(self.conv1(x)))        x = self.pool(self.relu(self.conv2(x)))        x = x.view(-1, 32 * 8 * 8)        x = self.fc1(x)        return xdef count_parameters(model):    total_params = 0    zero_params = 0    for name, module in model.named_modules():        if isinstance(module, (nn.Conv2d, nn.Linear)):            # 检查是否已经被剪枝            if hasattr(module, &#x27;weight_mask&#x27;):                total_params += module.weight_mask.numel()                zero_params += torch.sum(module.weight_mask == 0).item()            else:                total_params += module.weight.numel()                zero_params += torch.sum(module.weight == 0).item()    return total_params, zero_paramsdef apply_pruning(model, pruning_ratio):    for name, module in model.named_modules():        if isinstance(module, (nn.Conv2d, nn.Linear)):            prune.l1_unstructured(                module,                name=&#x27;weight&#x27;,                amount=pruning_ratio            )            # 打印每层的剪枝统计            mask = module.weight_mask            total = mask.numel()            zeros = torch.sum(mask == 0).item()            print(f&quot;Layer &#123;name&#125;:&quot;)            print(f&quot;总参数: &#123;total&#125;&quot;)            print(f&quot;被剪枝参数: &#123;zeros&#125;&quot;)            print(f&quot;层压缩率: &#123;zeros/total*100:.2f&#125;%\\n&quot;)# 测试代码model = SimpleCNN()print(&quot;剪枝前参数统计：&quot;)total, zeros = count_parameters(model)print(f&quot;总参数数量: &#123;total&#125;&quot;)print(f&quot;零参数数量: &#123;zeros&#125;&quot;)print(f&quot;初始压缩率: &#123;zeros/total*100:.2f&#125;%\\n&quot;)# 应用90%的剪枝率print(&quot;应用50%剪枝...&quot;)apply_pruning(model, 0.5)print(&quot;\\n剪枝后总体参数统计：&quot;)total, zeros = count_parameters(model)print(f&quot;总参数数量: &#123;total&#125;&quot;)print(f&quot;零参数数量: &#123;zeros&#125;&quot;)print(f&quot;最终压缩率: &#123;zeros/total*100:.2f&#125;%&quot;)\n\n量化是将模型的权重从32位浮点数转换为低位数值（如8位整数）的过程。\n可参考代码：https://github.com/BastianChen/Model-Compression-Demo/tree/master/quantization\n知识蒸馏这是一种将大模型（教师模型）的知识转移到小模型（学生模型）的方法\nimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torchvisionimport torchvision.transforms as transformsfrom torch.utils.data import DataLoader# 教师模型（与之前的SimpleCNN相同）class TeacherCNN(nn.Module):    def __init__(self):        super(TeacherCNN, self).__init__()        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)        self.fc1 = nn.Linear(32 * 8 * 8, 10)        self.relu = nn.ReLU()        self.pool = nn.MaxPool2d(2, 2)    def forward(self, x):        x = self.pool(self.relu(self.conv1(x)))        x = self.pool(self.relu(self.conv2(x)))        x = x.view(-1, 32 * 8 * 8)        x = self.fc1(x)        return x# 学生模型（更小的网络）class StudentCNN(nn.Module):    def __init__(self):        super(StudentCNN, self).__init__()        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)        self.fc1 = nn.Linear(16 * 8 * 8, 10)        self.relu = nn.ReLU()        self.pool = nn.MaxPool2d(2, 2)    def forward(self, x):        x = self.pool(self.relu(self.conv1(x)))        x = self.pool(self.relu(self.conv2(x)))        x = x.view(-1, 16 * 8 * 8)        x = self.fc1(x)        return xclass DistillationLoss(nn.Module):    def __init__(self, temperature=3.0):        super(DistillationLoss, self).__init__()        self.temperature = temperature    def forward(self, student_outputs, teacher_outputs, labels, alpha=0.5):        # 软目标损失        soft_targets = F.softmax(teacher_outputs / self.temperature, dim=1)        soft_prob = F.log_softmax(student_outputs / self.temperature, dim=1)        soft_targets_loss = -torch.sum(soft_targets * soft_prob) * (self.temperature ** 2)        # 硬目标损失        hard_loss = F.cross_entropy(student_outputs, labels)        # 组合损失        loss = (alpha * soft_targets_loss) + ((1 - alpha) * hard_loss)        return lossdef load_cifar10(batch_size=128):    transform = transforms.Compose([        transforms.ToTensor(),        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))    ])    trainset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=True,                                            download=True, transform=transform)    trainloader = DataLoader(trainset, batch_size=batch_size,                             shuffle=True, num_workers=2)    testset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=False,                                           download=True, transform=transform)    testloader = DataLoader(testset, batch_size=batch_size,                            shuffle=False, num_workers=2)    return trainloader, testloaderdef evaluate_model(model, dataloader, device):    model.eval()    correct = 0    total = 0    with torch.no_grad():        for data, labels in dataloader:            data, labels = data.to(device), labels.to(device)            outputs = model(data)            _, predicted = torch.max(outputs.data, 1)            total += labels.size(0)            correct += (predicted == labels).sum().item()    return 100 * correct / totaldef train_with_distillation(teacher_model, student_model, train_loader, test_loader,                            device, epochs=10, temperature=3.0, alpha=0.5):    teacher_model.to(device)    student_model.to(device)    teacher_model.eval()    student_model.train()    optimizer = torch.optim.Adam(student_model.parameters())    distillation_criterion = DistillationLoss(temperature=temperature)    best_acc = 0.0    for epoch in range(epochs):        running_loss = 0.0        for batch_idx, (data, target) in enumerate(train_loader):            data, target = data.to(device), target.to(device)            optimizer.zero_grad()            # 获取教师模型的输出            with torch.no_grad():                teacher_output = teacher_model(data)            # 获取学生模型的输出            student_output = student_model(data)            # 计算蒸馏损失            loss = distillation_criterion(student_output, teacher_output,                                          target, alpha=alpha)            loss.backward()            optimizer.step()            running_loss += loss.item()            if batch_idx % 100 == 99:                print(f&#x27;Epoch: &#123;epoch + 1&#125;, Batch: &#123;batch_idx + 1&#125;, &#x27;                      f&#x27;Loss: &#123;running_loss / 100:.4f&#125;&#x27;)                running_loss = 0.0        # 评估模型        student_acc = evaluate_model(student_model, test_loader, device)        teacher_acc = evaluate_model(teacher_model, test_loader, device)        print(f&#x27;\\nEpoch &#123;epoch + 1&#125;:&#x27;)        print(f&#x27;Teacher Accuracy: &#123;teacher_acc:.2f&#125;%&#x27;)        print(f&#x27;Student Accuracy: &#123;student_acc:.2f&#125;%&#x27;)        if student_acc &gt; best_acc:            best_acc = student_acc            torch.save(student_model.state_dict(), &#x27;best_student_model.pth&#x27;)    return student_model# 使用示例if __name__ == &#x27;__main__&#x27;:    device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)    # 加载数据    train_loader, test_loader = load_cifar10()    # 创建模型    teacher_model = TeacherCNN()    student_model = StudentCNN()    # 训练教师模型（这里假设已经训练好了）    # 实际使用时需要先训练教师模型    # 进行知识蒸馏    student_model = train_with_distillation(        teacher_model=teacher_model,        student_model=student_model,        train_loader=train_loader,        test_loader=test_loader,        device=device,        epochs=10,        temperature=3.0,        alpha=0.5    )    # 比较模型大小    def count_parameters(model):        return sum(p.numel() for p in model.parameters())    teacher_params = count_parameters(teacher_model)    student_params = count_parameters(student_model)    print(&quot;\\n模型大小比较：&quot;)    print(f&quot;教师模型参数数量: &#123;teacher_params:,&#125;&quot;)    print(f&quot;学生模型参数数量: &#123;student_params:,&#125;&quot;)    print(f&quot;压缩率: &#123;(1 - student_params / teacher_params) * 100:.2f&#125;% &quot;)\n\n优缺点：\n\n剪枝\n\n\n优点：实现简单，可以显著减少模型大小\n缺点：可能需要反复尝试以找到最佳剪枝比例\n\n\n量化\n\n\n优点：显著减少模型存储空间和推理时间\n缺点：可能导致精度轻微下降\n\n\n知识蒸馏\n\n\n优点：可以得到更小但性能相近的模型\n缺点：需要训练过程，实现相对复杂\n\n \\4.  NAS神经架构搜索\n优点：\n\n自动化设计，减少人工干预。\n可能发现人类难以设计的高性能架构。\n\n缺点：\n\n计算成本高，需要大量计算资源。\n搜索过程耗时。\n\n神经架构搜索（neural architecture search， NAS）是一种利用强化学习方法同时学习模型架构和相应参数的方法。简单来说，就是在一个定义好的搜索空间内，通过一定的搜索策略，得到最终表现最好的网络。通过加入准确率、推理延迟等指标，网络架构搜索产生的网络结构在轻量化应用中能获得更高的竞争力。\nimport torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import DataLoaderfrom torchvision import datasets, transforms# 定义搜索空间class ConvBlock(nn.Module):    def __init__(self, in_channels, out_channels, kernel_size):        super(ConvBlock, self).__init__()        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)        self.relu = nn.ReLU()        self.pool = nn.MaxPool2d(2)    def forward(self, x):        x = self.conv(x)        x = self.relu(x)        x = self.pool(x)        return x# 定义候选架构def create_model(kernel_size, channels):    model = nn.Sequential(        ConvBlock(1, channels[0], kernel_size),        ConvBlock(channels[0], channels[1], kernel_size),        nn.Flatten(),        nn.Linear(channels[1] * 7 * 7, 10)  # 假设输入是 28x28    )    return model# 加载数据transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])train_data = datasets.MNIST(root=&#x27;./data&#x27;, train=True, download=True, transform=transform)train_loader = DataLoader(train_data, batch_size=64, shuffle=True)# 随机搜索策略def random_search(search_space, num_trials=10):    best_accuracy = 0    best_model = None    for _ in range(num_trials):        # 随机选择超参数        kernel_size = search_space[&#x27;kernel_sizes&#x27;][torch.randint(0, len(search_space[&#x27;kernel_sizes&#x27;]), (1,)).item()]        channels = [search_space[&#x27;channels&#x27;][torch.randint(0, len(search_space[&#x27;channels&#x27;]), (1,)).item() for _ in range(2)]        # 创建模型        model = create_model(kernel_size, channels)        optimizer = optim.Adam(model.parameters(), lr=0.001)        criterion = nn.CrossEntropyLoss()        # 训练模型        for epoch in range(2):  # 简单训练 2 个 epoch            for inputs, labels in train_loader:                optimizer.zero_grad()                outputs = model(inputs)                loss = criterion(outputs, labels)                loss.backward()                optimizer.step()        # 评估模型        correct = 0        total = 0        with torch.no_grad():            for inputs, labels in train_loader:                outputs = model(inputs)                _, predicted = torch.max(outputs, 1)                total += labels.size(0)                correct += (predicted == labels).sum().item()        accuracy = correct / total        # 更新最佳模型        if accuracy &gt; best_accuracy:            best_accuracy = accuracy            best_model = model    return best_model, best_accuracy# 定义搜索空间search_space = &#123;    &#x27;kernel_sizes&#x27;: [3, 5],    &#x27;channels&#x27;: [16, 32, 64]&#125;# 执行随机搜索best_model, best_accuracy = random_search(search_space)print(f&#x27;Best Accuracy: &#123;best_accuracy:.4f&#125;&#x27;)print(best_model)\n\n","tags":["tools"]},{"title":"LPSNet","url":"/2024/03/16/LPSNet/","content":"Lightweight and Progressively-Scalable Networks for Semantic SegmentationAbstract(摘要)主要方法：通过一次性扩展单个维度（卷积块的数量、通道的数量或输入分辨率）来逐步将小型网络扩展到更大的网络，以满足最佳速度&#x2F;精度权衡。\nConclusion and Discussion（总结和讨论）它是一种探索经济设计并逐步扩大网络以实现有效的语义分割\n可能影响精度&#x2F;延迟的平衡的因素为：多路径框架中的基本卷积块和路径交互方式\n在卷积块中使用3×3Conv和双线性插值实现跨路径的交互\n（上采样换成PointRend会怎样？）\n先构建一个微型网络，然后一次性扩展单个维度将微型网络扩展为一系列较大的网络\nIntroduction（引言）语义分割是为图像分割或视频帧的每个像素分配语义标签\n多尺度学习沿三个不同维度进行语义分割：\n\nU-shape(结构分层融合特征，逐步提高空间分辨率)\npyramid pooling（在多个尺度上执行空间或空洞空间金字塔池化深入研究金字塔信息）\nmuti-path framework（将输入图像的大小调整为多个分辨率或尺度，并将每个尺度输入到深度学习的单独路径中）\n\n本文使用的就是muti-path framework，将输入分辨率从高到低并行放置，直接保持高分辨率信息，这样学习到的特征可能更有能力对每个像素进行分类和定位\n\n轻量化用于语义分割的计算单元\n逐步扩大网络，同时平衡准确性和推理延迟\n\n一次性扩展单个维度（卷积块的数量、通道的数量或输入分辨率）\n\ncontributions:(1) The lightweight design of convolutional blocks and the way of path interactions in multipath framework are shown capable of regarding as the practical principles for efficient semantic segmentation; （卷积块的轻量化设计和多路径框架中的路径交互方式实用）\n(2) The exquisitely devised LPS-Net is shown able to progressively expand the network complexity while striking the right accuracy-efficiency tradeoff; （可扩展网络复杂性）\n(3) LPSNet has been properly verified through extensive experiments over three datasets, and superior capability is observed on both NVIDIA GPUs and embedded devices in our experiments.（结果很不错）\nResults（结果）\nMethods（方法）Macro Architecture（employs the multi-path recipe）LPS-Net 中采用多路径配方的宏架构\n\n（轻量化）三个设计原则：（卷积类型、通道数数量、跨多个路径的交互方式）\n将输入图像的大小调整为多个尺度，并将每个尺度反馈送到单独的路径中。\n将交互模块放置在阶段 3∼5 的末尾，旨在促进路径之间的相互交互。所有路径的输出被聚合并输入到分割头中，以生成具有 num 类通道的分数图。\n对分数图执行双线性上采样，产生分辨率为 H×W 的输出，与输入分辨率完全匹配\n卷积块\n卷积块的类型\n\n通过实验选择用标准卷积作为 LPSNet 中的构建块\n\n通道数\n\n具有 2n-divisible 通道宽度的卷积的可并行化实现。因此，将 LPSNet 中卷积的通道宽度设为2n-divisible，其中 n 尽可能大。\nMulti-Path交互\n\n扩展算法\n","tags":["论文阅读"]},{"title":"PointRend","url":"/2024/03/22/PointRend/","content":"PointRend: Image Segmentation as Rendering现有方法：一般会输出一个原图1&#x2F;8或1&#x2F;16大小的预测图，然后通过双线性插值来补齐最后的8x&#x2F;16x分辨率\n现有方法存在的问题\n过采样：对于图片中低频区域，没必要用太多的采样点，却使用太多采样点造成过采样；欠采样 ：对于图片中高频区域（ 靠近物体边界 ），这些区域的采样过于稀疏，导致分割出的边界过于平滑。\nPointRend\n提出的 PointRend 是一个通用的模块，它允许许多可能的实现：输入一个或多个 feature map（通常比原图分辨率低 4x 或 16x），输出高分辨率的预测结果.\n\nPointRend 只对选择的点进行预测，而不是对所有输入点都进行预测.\n\n对选择的点先通过插值的方式提取点特征，然后用 point head subnetwork 来预测点标签\n\n\n\nInference\n每个迭代循环中：① 用双线性插值对上次预测出的 seg mask 进行上采样；② 然后在上采样后的 mask 中找出 N 个最不确定的点（比如 binary mask 中 pribabilities 接近 0.5 的点）；③ 用 pointrend 提取这些点的 feature 并预测它们的 label.\n\n采样的三个原则\n过生成: 从均匀分布中随机抽取 KN（K&gt;1）个点作为候选点。\n重要性抽样: 插值得到所有 KN 点处的的粗预测，然后计算这些点的不确定性，选择其中最不确定的 βN ( β∈[0,1] ) 个点。\n广域覆盖: 剩下的 (1−β)N 个点从均匀分布中随机采样得到\n\nCoarse prediction features\n必要性：只有点特征是不够的，因为 ① 对实例分割而言，一个点可能在两个实例的交叠处，需要区域信息来辅助判断；② 对实例分割和语义分割两项任务而言，点特征所使用的 feature map 可能只包含 low-level 的信息，因此还需要包含进去一些上下文和语义信息.\n因此使用粗分割结果作为辅助信息，被涵盖在点特征表示向量中：一个点处表示 K 分类结果的 K 维向量.\nPoint Head\n2 个 1024-wide hidden layers 的 MLP\n类似于图卷积或 PointNet，这个 MLP 对所有的点共享参数.\n","tags":["论文阅读"]},{"title":"RTSeg","url":"/2023/11/16/RTSeg/","content":"RTSeg: Real-time Semantic Segmentation Comparative Study这一篇更加关注计算效率，以下是一些些翻译加一些些理解。\n针对于编码和解码模块设计出了可以灵活替换的子模块，方便大家可以方便的替换编码或者解码模块，从而针对不同任务设计不同的网络结构。\nABSTRACT（摘要）Semantic segmentation benefits robotics related applications, especially autonomous driving. Most of the research on semantic segmentation only focuses on increasing the accuracy of segmentation models with little attention to computationally efficient solutions. The few work conducted in this direction does not provide principled methods to evaluate the different design choices for segmentation. In this paper, we address this gap by presenting a real-time semantic segmentation benchmarking framework with a decoupled design for feature extraction and decoding methods. The framework is comprised of different network architectures for feature extraction such as VGG16, Resnet18, MobileNet, and ShuffleNet. It is also comprised of multiple meta-architectures for segmentation that define the decoding methodology. These include SkipNet, UNet, and Dilation Frontend. Experimental results are presented on the Cityscapes dataset for urban scenes. The modular design allows novel architectures to emerge, that lead to 143x GFLOPs reduction in comparison to SegNet. This benchmarking framework is publicly available at 1 .\n在语义分割上大多数都是提升精度，但是很少关注计算效率高的解决方案，针对这一空白，提出了一个实时语义分割基准框架，对特征提取和解码进行了解耦设计。\n特征提取用了不同的网络结构：VGG16、Resnet18、MobileNet和ShuffleNet；解码是由多个用于分割的元架构定义的：SkipNet、UNet和Dilation Frontend。\nINTRODUCTION（介绍）\n主要贡献：\n\n将特征提取模块和解码器进行了模块化解耦，并将器成为元架构（有助于理解网络不同部分对实时性能的影响）\n消融实验突出了精度和速度的平衡\n我们框架的模块化设计出现了两种新颖的分割架构，分别使用MobileNet [14] 和具有多种解码方法的 ShuffleNet [15]。与 SegNet 相比，ShuffleNet 减少了 143 倍的 GFLOPs。\n\nSkipNet解码器模块介绍\n 图2（a）是SkipNet的解码结构，类似于FCN8s的结构，其中较高高分辨率的特征图通过1x1卷积来将通道数量减少到最终的类别数量，每一个通道都对应着一个类别。\n图2（b）是UNet的解码结构，Unet结构提供的解码方式为：利用反卷积，将与下采样阶段对应的特征图进行上采样。上采样的特征图与下采样中有相同分辨率的特征图进行融合。逐级向上采样提供的精度比一次8倍向上采样的精度更高。目前采用的融合方法是逐元素相加，concatenation的方法可以提供更高的准确率，因为其确保了网络能够学习特征的加权融合，但是这样会增加计算量(concatenation会改变通道数量)。上采样之后的特征最后会接一个1x1的卷积来输出最后的逐元素分类。\n对于Dilation Frontend的解码结构，文中并没有给出示意图，Dilation Frontend结构利用了空洞卷积来取代下采样。空洞卷积确保了网络能够保留足够的感受野的同时，不会降低特征图的分辨率。但是副作用就是计算量的增加，修改编码器网络使得下采样率从32变为8。下采样的减少是通过删除池化层或将步幅为2的卷积转换为步幅为1的卷积来完成的。然后，将池化或正常的卷积替换为两个空洞率为2和4的空洞卷积[3]。\n","tags":["论文阅读"]},{"title":"SAM","url":"/2024/08/20/SAM/","content":"Segment Anything\nTask（提示分割任务）作为预训练，流程就是：给一个prompt（提示）和对应的图，返回一个有效的掩码。\n仔细解释一下，\n\nprompt只是指定在图像中分割什么。\n\n有效输出掩码意味着，即使给的提示不明确甚至可能涉及多个对象，输出也应该是一个合理的掩码的至少其中一个对象。\n\n\nModel（SAM）首先要满足三个条件：\n\n必须支持灵活的提示\n需要实时计算掩码以允许交互使用\n必须具有模糊意识\n\n流程如下：prompt进入提示编码器嵌入提示，image进入图像编码器计算图像嵌入，然后将两个信息源组合在一个轻量级掩码解码器中（在解码器里预测分割mask），然后输出一个有效的掩码。\n在这其中，可以使用不同的prompt搭配相同的图像嵌入。\n为了SAM能够更好的感知处理歧义，作者还预测单个提示的多个掩码。\n细节：\n\nImage encoder(图像编码器)：使用MAE预训练的vit，为了处理高分辨率输入。\nPrompt encoder(提示编码器)：使用CLIP中现成的文本编码器对每种提示类型和自由格式文本进行学习嵌入。使用卷积嵌入mask，然后与图像嵌入按元素求和（add）。\nMask decoder(掩码编码器)：掩码解码器有效地将图像嵌入、提示嵌入和输出标记映射到掩码。\n过程：采用了 Transformer 解码器块 的修改，后跟动态掩模预测头。修改后的解码器块使用两个方向的即时自注意力和交叉注意力（即时图像嵌入，反之亦然）来更新所有嵌入。运行两个块后，我们对图像嵌入进行上采样，并且 MLP 将输出标记映射到动态线性分类器，然后计算每个图像位置的掩模前景概率。\nResolving ambiguity（解决歧义）：改成预测单个提示的多个输出掩码，发现三个掩码输出足以解决最常见的问题（整体、部分、子部分）\nLosses：我们使用焦点损失和骰子损失的线性组合来监督掩模预测。\nData（Data engine数据引擎 &amp; Dataset）为了构建了一个数据引擎，分为三个阶段：辅助手动、半自动和全自动。\n在第一阶段，SAM 协助注释者注释掩模，类似于经典的交互式分割设置。\n在第二阶段，SAM 可以通过提示可能的对象位置来自动为对象子集生成掩码，而注释器则专注于注释其余对象，从而帮助增加掩码多样性。\n在最后阶段，我们使用前景点的规则网格提示 SAM，每张图像平均产生 大概100 个高质量掩模。\n数据集是SA-1B，包括来自 11M 许可和隐私保护图像的超过 1B 个掩码。\n","tags":["论文阅读"]},{"title":"SQL注入","url":"/2024/11/02/SQL%E6%B3%A8%E5%85%A5/","content":"SQL注入分类SQL注入按照类型分为数字型注入和字符型注入。注入点的数据类型为数字型时为数字型注入，注入点的数据类型为字符型为字符型注入。 SQL注入按照服务器返回信息是否显示分为报错注入和盲注。如果在注入的过程中，程序将获取的信息或者报错信息直接显示在页面中，这样的注入为报错注入；如果在注入的过程中，程序不显示任何SQL报错信息，只能通过精心构造SQL语句，根据页面是否正常返回或者返回的时间判断注入的结果，这样的注入为盲注。\n数字型注入数字型注入就是注入点的数据类型是数字型，没有用单引号引起来。数字型注入的典型示例代码\n$id = $_GET[&#x27;id&#x27;];$sql = &quot;SELECT * FROM users WHERE id=$id LIMIT 0,1&quot;;$result = mysql_query($sql);$row = mysql_fetch_array($result)\n\n判断数字型注入的方法如下 1. 输入单引号，不正常返回 如果用户提交index.php?id&#x3D;1’，那么后面的SQL语句就变成为SELECT * FROM users WHERE id&#x3D;1’ LIMIT0,1,SQL语句本身存在语法错误，会有不正常的结果返回。 2. 输入and 1&#x3D;1，正常返回 如果用户提交index.php?id&#x3D;1 and 1&#x3D;1，那么后面的SQL语句就变成为SELECT * FROM users WHERE id&#x3D;1 and 1&#x3D;1 LIMIT 0,1，会有正常的结果返回。 3. 输入and 1&#x3D;2，不正常返回 SQL语句变为SELECT * FROM users WHERE id&#x3D;1 and 1&#x3D;2 LIMIT 0,1,会有不正常的结果返回。\n字符型注入字符型注入就是注入点的数据类型是字符型。字符型注入与数字型注入的区别就是字符型注入要用一对单引号引起来。字符型注入的典型示例代码如下：\n$id = $_GET[&#x27;id&#x27;];$sql = &quot;select * from users where id=&#x27;$id&#x27; limit 0,1;$result = mysql_query($sql);$row = mysql_fetch_array($result);\n\n判断字符型注入的方法如下 1. 输入单引号，不正常返回 输入单引号后，SQL语句变为select * from users where id&#x3D;1’ limit 0,1，SQL语句本身存在语法错误，会有不正常的结果返回 2. 输入’ and ‘1’&#x3D;’1，正常返回 SQL语句变为select * from users where id&#x3D;’1’ and ‘1’&#x3D;’1’ limit 0,1，会有正常结果返回。 3. 输入’ and ‘1’&#x3D;’2，会不正常返回 SQL语句变为select * from users where id&#x3D;’1’ and ‘1’&#x3D;’2’ limit 0,1，会有不正常的结果返回\n","tags":["notes"]},{"title":"SAM 2","url":"/2024/08/22/SAM2/","content":"Segment Anything in Images and VideosIntroduction(介绍)比起SAM，SAM2可以看作是SAM的拓展，从静态的图像分割，到动态的视频分割。准确度和速度都提升了。\n（未完待续）\n","tags":["论文阅读"]},{"title":"汇编","url":"/2025/03/17/Simple-assembly-learning/","content":"这里简单记录一下汇编的学习，本地环境为Windows，使用的工具有DOSBox、MASM5…\n环境安装8086汇编语言需要在DOS环境下进行，因此需要在电脑上安装一个DOS虚拟机。虚拟机软件选用DOSBox-x 0.83.19，该软件为绿色软件，将压缩包解压后运行文件夹中的DosBox-x程序即可。\nDOS环境搭好后需要安装宏汇编开发包MASM5，具体方法为：\n\\1) 在本机硬盘上创建一个DOS目录，如D:\\DOS ；\n\\2) 将MASM5.RAR复制到该目录并解压 ；\n这里注意的是，masm的路径应该直接为D:\\DOS:\\MSAM5,里面包含masm.exe、link.exe、 debug.exe、 exe2bin.exe，分别用于汇编asm程序、连接、调用。\n\\3) 编辑DOSBOX-X目录下的 dosbox-x.conf 文件：\n​    在文件末尾[autoexec]段落（功能是开机自动运行）下添加一行：\nmount c d:\\dos\n\n​    该行将你的DOS目录映射为DOS虚拟机的C盘。\n​    然后在上面若干行处将\nset path  = Z:\\;Z:\\SYSTEM;Z:\\BIN;Z:\\DOS;Z:\\4DOS;Z:\\DEBUG;Z:\\TEXTUTIL\n\n​    这一行修改为\nset path  = Z:\\;Z:\\SYSTEM;Z:\\BIN;Z:\\DOS;Z:\\4DOS;Z:\\DEBUG;Z:\\TEXTUTIL;C:\\MASM5\n\n​    这样即可将宏汇编MASM5的功能加入搜索路径，输入命令即可使用。\n\\4) 存盘退出，启动虚拟机即可\n可以在DOS盘下建立一个exp目录，将实验程序源代码都存在目录里。源代码的编写用任何文本编辑软件编写均可。\n至此汇编语言开发环境搭建完毕。\n单代码段程序的编写编写汇编程序在记事本中写入汇编程序，并修改后缀名为.asm，存放在建立的D:\\DOS:\\exp中\n汇编文件点开解压之后的dosbox文件夹，双击exe打开，cd到存放文件的地方，输入masm回车，在之后的语句输入上述已编写的asm文件名（不需要后缀）然后连续敲回车，显示0 Warning/Severe Errors表明汇编成功，生成一个后缀为.obj文件（也可以检查一下masm是否可用）\n还可以直接输入 masm  [文件名]\n以下是我输入的例子：\nassume cs:codesgcodesg segmentmov ax, 2000Hmov ss,axmov sp, 0add sp, 10pop axpop bxpush axpush bxpop axpop bxmov ax, 4c00Hint 21Hcodesg endsend\n\n\n连接文件在汇编完成的语句后输入link，之后再输入文件名，连续敲回车，显示LINK:warning L4021:no stack segment表明连接成功，可以看到后缀为.exe的文件\n同样也可以直接输入 link [文件名]\n\n调试文件输入debug [文件名].exe就可以进入调试，在短横线后输入命令即可。\n以下为常用命令：\nr：查看、改变寄存器的内容查看就输入r，修改就输入r [需要修改的寄存器名字] ，然后输入修改的数值即可完成。\n\nd：查看内存中的内容直接输入d，可以查看预设地址内存处的128个字节的内容\n\n也可以查看指定段的，输入d [后]:[前]\n\ne：修改内存单元中的内容可以写入数据、指令，内存中，数据和指令都是机器码，没什么区别\n写入数据（需要指明地址和要写入的地址）e  [地址] [数据](数据如果有多个，中间要加空格)\n\n\n逐个询问修改数据e [地址]\n\n输入这个地址就会告诉你这个地址的内容，修改就在后面写上需要修改的数据，如果想对下一个字节进行修改，敲空格即可跳到下一个地址\n\nu：将内存中的机器指令翻译成汇编指令\na：以汇编的指令格式在内存中写入机器指令a [写入的地址][内容]...(按回车退出)\n\nt：单步运行\n注意观察每次输入t指令后，ax，bx的值变化。可以观察出t命令是使用一次执行一次汇编指令。\nq：退出debug​\t\n"},{"title":"SkipNet","url":"/2023/11/16/SkipNet/","content":"SkipNet代码：https://github.com/ucbdrive/skipnet\nAbstract. （摘要）While deeper convolutional networks are needed to achieve maximum accuracy in visual perception tasks, for many inputs shallower networks are sufficient. We exploit this observation by learning to skip convolutional layers on a per-input basis. We introduce SkipNet, a modified residual network, that uses a gating network to selectively skip convolutional blocks based on the activations of the previous layer. We formulate the dynamic skipping problem in the context of sequential decision making and propose a hybrid learning algorithm that combines supervised learning and reinforcement learning to address the challenges of non-differentiable skipping decisions. We show SkipNet reduces computation by 30 − 90% while preserving the accuracy of the original model on four benchmark datasets and outperforms the state-of-the-art dynamic networks and static compression methods. We also qualitatively evaluate the gating policy to reveal a relationship between image scale and saliency and the number of layers skipped.\n尽管需要更深的卷积网络才能在视觉感知任务中获得更大的准确性，但对于大多数输入来说，较浅的网络就够了。\nSkipNet是经过改进的残差网络，使用gating network根据前一层的激活有选择地跳过卷积层。我们在顺序决策（sequential decision）的背景下制定动态跳过（dynamic skipping）问题，并提出一种混合学习算法，将监督学习和强化学习相结合，以解决不可微分的跳过动态的问题。\n计算量减少了30%至90%，同时在四个基准数据集上保留了原始模型的准确性，并且胜过了最新的动态网络和静态压缩方法。\n定性评估gating策略，以揭示图像比例和显着性（saliency）与跳过的层数之间的关系。\nIntroduction（介绍）\n动态选择在推理过程中应跳过卷积神经网络的哪些层，动态跳过问题-构造-&gt;顺序决策问题，其中前一层的输出决定是否绕过后一层。\n动态跳过问题的目标是保留整个网络准确性的同时，跳过尽可能多的层。（减少参数量，观察每层的作用）\n为了在保持准确性的同时减少计算量，我们需要正确绕过网络中不必要的层，学习有效的跳过策略也是一项挑战。\n（同时因为会跳过层数，所以不能应用梯度的优化）\n过程：将gating module明确分配给每组卷积层（each group of layers）。gating模块将前一层的激活映射到二进制决策，以跳过或执行后一层。我们分两个阶段训练门控模块。首先，我们通过采用重新参数化(reparametrization)技巧对二进制skip决策使用soft-max松弛，并结合原始模型使用的标准交叉熵损失一起训练layers and gates。然后，我们将概率gate输出视为初始跳过策略，并在不使用relaxation的情况下使用REINFORCE来优化策略。在后期阶段，我们共同优化跳过策略和预测误差，以稳定探索过程。\nRelated Work（相关工作）加速现有的卷积网络：（训练初始网络后使用）权重稀疏化、滤波器修剪、矢量量化和蒸馏-&gt;将模型转移到较浅的网络上进行模型压缩\n他人实验探索：通过提早终止来动态缩放计算、暂停循环网络以节省计算成本、在卷积网络中使用尽早终止、ResNets每组块中的提前终止\nSkipNet并不会提早退出，而是根据处理层的输出有条件地绕过各个层，可以更好地权衡成本\nSkipNet Model Design（模型构思）\n对于给定输入有选择地包括或排除了各个层。 使用插入在各层之间的小型门控网络可以完成各层的按输入选择。 gating网络将前一层或一组层的输出映射到一个二进制决策，以执行或绕过后一层或一组层\n对于a，当gating module独立的时候，情况变复杂的时候参数量变多\nGating Network Design","tags":["论文阅读"]},{"title":"VAE","url":"/2024/11/10/VAE/","content":"VAE 是一种生成式人工智能算法，它利用深度学习生成新内容、检测异常并去除噪音。\n适合生成用于训练其他人工智能算法的合成时间序列数据，也适用于生成文本、图像和视频。不过，在生成不同类型的内容，它们更有可能成为其他模型的补充，如 GAN、稳定扩散（扩散模型的一种创新）和转换器。\nVAE结合了两种类型的神经网络，一个网络（编码器）能够找到将原始数据编码到潜在空间的更好方法，第二个网络（解码器）能找到将这些潜在表征转化成新内容的更好方法。GAN类似，第一个神经网络找到生成虚假内容的更好方法，第二个神经网络找到检测虚假内容的更好方法。\n自动编码器介绍自动编码器有助于创建用于压缩数据和检测异常的编解码器。早期应用于降维和特征学习，目前可集成到其他AI或机器学习算法中提高精度和性能。（比如提取人声和音乐）\n自动编码器的类型基本自动编码器有几种类型，包括以下几种：\n\n稀疏自动编码器。这是最古老和最流行的方法之一。它们适用于特征提取、降维、异常检测和迁移学习。它们使用技术来鼓励神经网络仅使用中间神经元的子集。这些未使用的神经元的剩余部分使它们能够灵活地识别和学习更有效的数据表示。\n去噪自动编码器。它们学习从嘈杂的数据流中重建原始数据的方法。它们通常用于清理低光图像、识别语音和预处理物联网数据。\n收缩式自动编码器。它们专门学习一种能够适应输入数据细微变化的表示。这有助于它们更好地适应未见数据。研究人员使用它们通过突出显示数据集中负责结果的最显着特征来提高神经网络模型的可解释性。\n\n","tags":["notes"]},{"title":"Yolov10","url":"/2024/05/26/Yolov10%E5%B0%8F%E7%9F%A5%E8%AF%86/","content":" 今天突然发现都出了YOLOv10了，技术真的变更的好快，以下是本人学习的一些小知识。\n为了提升性能效率边界，这一次改进的是后处理和模型架构。\n在原来，YOLO后处理依赖着非极大值抑制（NMS），性能对NMS的超参数敏感，阻碍了YOLO的端到端部署，产生了一定的推理延迟。\n增强特征提取能力可以考虑以下模块：DarkNet、CSPNet、EfficientRep和ELAN等\nDarkNet是yolov3里面的backbone，主要是由重复堆叠下采样卷积+n*残差块组成。主要是由cnn卷积核提取特征。\n\nCSPNet的主要目的是使该体系结构能够实现更丰富的梯度组合，同时减少计算量。\n增强多尺度特征融合：PAN、BiC、GD和RepGFPN等\n模型缩放策略和重新参数化技术\n","tags":["论文阅读"]},{"title":"WTConv","url":"/2024/10/12/WTConv/","content":"Abstract(摘要)新提出的WTConv（小波卷积）可以获得非常大的感受野而不会受到过度参数化的影响。\nDiscussion（讨论）使用WTConv，我们可以以纯卷积方法配置全局感受野的空间混合。\nWTConv 大大增加了 CNN 的有效感受野，改善了 CNN 的形状偏差，使网络对损坏更加鲁棒，并为各种视觉任务提供了更好的性能。\nLimitations(限制)运行时间在现有框架内相对较高，这是由于多个顺序操作（WT-conv-IWT）的开销造成的，这可能比本身的成本更高。\n可以通过使用专门的实现来缓解，例如，在每个级别中与卷积并行执行 WT 以减少内存读取，或就地执行 WT 和 IWT 以减少内存分配。\nIntroduction（导言）一开始，大家认为vit的多头自注意力层有利于特征的全局混合，而卷积在结构上仅限于特征的局部混合。（性能差距）为了弥补性能差距，把卷积核增大到7×7大小，但是内核会变得过度参数化，并且在达到全局感受野之前性能会饱和。\n发现，使用较大的内核使 CNN 的形状偏差更大，这意味着它们捕获图像中低频的能力得到了提高。但是卷积层通常倾向于响应输入中的高频。而注意力头更适合低频。\n所以\nidea：利用时频分析中的小波变换（WT），使卷积的感受野能够很好地放大，并通过级联引导 CNN 更好地响应低频。\nmovivation：保留了一定的空间分辨率，这使得空间运算（比如卷积）更加有意义。\n提出了 WTConv，该层使用级联 WT 分解并执行一组小核卷积，每个卷积都专注于越来越大的感受野中输入的不同频段。这个过程使我们能够更加重视输入中的低频，同时仅添加少量可训练参数。（感受野大，参数量少）\n对于k×k感受野，参数量随k呈对数增长。\nTo summarize, our key contributions are:（主要贡献）\n – A new layer, called WTConv, that uses the WT to increase the receptive field of convolutions effectively. （有效地增加卷积的感受野）\n– WTConv is designed to be a drop-in replacement (for depth-wise convolutions) within given CNNs. （WTConv可替代CNN的Conv）\n– Extensive empirical evaluation demonstrates that WTConv improves CNNs’ results in several key computer-vision tasks. （改善cv任务的结果）\n– Analysis of WTConv’s contribution to CNN’s scalability, robustness, shapebias, and ERF.（可扩展性、鲁棒性）\nMethods（方法）Preliminaries: The Wavelet Transform as Convolutions(小波变换)\n我们在两个维度上操作，使用以下四个滤波器组产生步幅为 2 的深度卷积：\n\nfLL为低通滤波器，其余三个为高通滤波器，对于每个输入通道，卷积的输出：\n\nXLL 是 X 的低频分量，而 XLH 、 XHL 、 XHH 是其水平、垂直和对角高频分量。由于公式（1）中形成了正交基，所以应用小波逆变换（IWT）通过转置卷积得到X：\n\n然后通过递归分解低频分量给出级联小波分解。每个分解级别由下式给出：\n\n由迭代分解低频分量可以分析出，小波变换更加关注于低频，较低频率的频率分辨率增加，空间分辨率降低。输入低频的重复小波变换分解强调了它们并增加了层的相应响应。\nConvolution in the Wavelet Domain（小波域中的卷积）已知，增加卷积核的大小时参数量以2次方增长，为了缓解这种情况，使用小波变换来过滤和缩小输入的低频和高频内容。然后，在使用 IWT 构造输出之前，对不同频率图执行小内核深度卷积。\n\nX 是输入张量，W 是 k × k 深度内核的权重张量，其输入通道数是 X 的四倍。（刚好和分离出来的不同频率分量的卷积相匹配）该操作分离了频率分量之间的卷积，还允许较小的内核在原始输入的较大区域中进行操作。\n采用该 1 级组合运算，并使用等式 1 中相同的级联原理进一步增加等式4，该过程由下式给出：\n\n X(0) LL 是层的输入，X(i) H 表示级别 i 的所有三个高频图X(i)LH,X(i)HL,X(i)HH。\n为了组合不同频率的输出, WT 及其逆是线性运算,意味着 IWT(X + Y ) &#x3D; IWT(X) + IWT(Y )，所以得到：\n\n Z(i) 是从级别 i 开始的聚合输出。不同大小卷积的两个输出相加作为输出。\n例：使用 2 级小波分解和 3 × 3 卷积核大小。\n\n不能对 Y (i) LL 、 Y (i) H 中的每一个进行归一化，因为它们的单独归一化并不对应于原始域中的归一化。仅执行通道缩放来权衡每个频率分量足够。\nThe Benefits of Using WTConv（使用WTConv的好处）将 WTConv 合并到给定的 CNN 中有两个主要的技术优势：\n\nWT 的 l 级级联频率分解，与每个级别的固定大小内核 k 一起，允许参数数量在级别数中线性缩放而感受野呈指数增长。\nWTConv 层的构建比标准卷积更好地捕获低频。因为输入低频的重复小波变换分解强调了它们并增加了层的相应响应。\n\nComputational Cost（计算成本）深度卷积的计算成本为\n\n其中 C 是输入通道数，(NW , NH ) 是输入的空间维度，(KW , KH ) 是内核大小，(SW , SH ) 是每个维度的步幅。\n通过使用标准卷积运算的简单实现，WT 的 FLOP 计数为\n\n因为四个内核的大小为 2×2，每个空间维度上的步幅为 2，并且在每个输入通道上运行。\n比较起来，这仍然比类似感受野的标准深度卷积节省了很多。\nResults（结果） 形状偏差\n\n形状偏差与人类的感知有关，被认为是比较理想的。\n消融实验\n\n","tags":["论文阅读"]},{"title":"about_conda","url":"/2024/07/09/about-conda/","content":"记录一下常用的conda命令\n查看版本\nconda --version\n\n查看环境配置\nconda config --show\n\n更新conda\nconda update conda\n\n创建虚拟环境\nconda create -n env_name python=3.9\n\n查看虚拟环境\nconda env listconda info -econda info --envs\n\n激活虚拟环境\nconda activate env_name\n\n退出虚拟环境\nconda deactivate\n\n删除虚拟环境\nconda remove --name env_name --all\n\n删除虚拟环境中的某些包\nconda remove --name env_name  package_name\n\n查看环境中有的包\nconda list\n\n克隆虚拟环境\nconda create -n BBB --clone AAA\n\n在本地的conda环境AAA，克隆给新环境BBB\n","tags":["工具使用"]},{"title":"attention_use","url":"/2025/03/07/attention-use/","content":"这是一个模块替换的测试，以下代码使用paddlepaddle框架\ndual \nclass AttentionBlock(nn.Layer):    def __init__(self, F_g, F_l, F_out):        super().__init__()        self.W_g = nn.Sequential(            nn.Conv2D(                F_g, F_out, kernel_size=1, stride=1, padding=0),            nn.BatchNorm2D(F_out))        self.W_x = nn.Sequential(            nn.Conv2D(                F_l, F_out, kernel_size=1, stride=1, padding=0),            nn.BatchNorm2D(F_out))        self.psi = nn.Sequential(            nn.Conv2D(                F_out, 1, kernel_size=1, stride=1, padding=0),            nn.BatchNorm2D(1),            nn.Sigmoid())        self.relu = nn.ReLU()    def forward(self, g, x):        g1 = self.W_g(g)        x1 = self.W_x(x)        psi = self.relu(g1 + x1)        psi = self.psi(psi)        res = x * psi        return res\n\n","tags":["tools"]},{"title":"python笔记","url":"/2024/10/18/python%E7%AC%94%E8%AE%B0/","content":"运算符重载python的运算符用于内置类，但是相同的运算符对不同类型有不同的行为，python中的这一功能允许同一运算符根据上下文具有不同的语义，称为运算符过载。\nPython中的特殊函数以双下划线__开头的类函数在Python中称为特殊函数。每次我们创建该类的新对象时都会调用它。Python中有很多特殊函数。\n在类中定义 __str()__方法，可以控制他的打印输出方式。\nclass Point:    def __init__(self, x = 0, y = 0):        self.x = x        self.y = y        def __str__(self):        return &quot;(&#123;0&#125;,&#123;1&#125;)&quot;.format(self.x,self.y)\n\ntry：\n&gt;&gt;&gt; p1 = Point(2,3)&gt;&gt;&gt; print(p1)(2,3)\n\n重载 +（实现 __add__()函数）class Point:    def __init__(self, x = 0, y = 0):        self.x = x        self.y = y        def __str__(self):        return &quot;(&#123;0&#125;,&#123;1&#125;)&quot;.format(self.x,self.y)        def __add__(self,other):        x = self.x + other.x        y = self.y + other.y        return Point(x,y)\n\ntry:\n&gt;&gt;&gt; p1 = Point(2,3)&gt;&gt;&gt; p2 = Point(-1,2)&gt;&gt;&gt; print(p1 + p2)(1,5)\n\npython运算符重载的特殊函数\n\n\n运算符\n表达\n在内部\n\n\n\n相加（+）\np1 + p2\np1 .__ add __（p2）\n\n\n相减（-）\np1-p2\np1 .__ sub __（p2）\n\n\n相乘（*）\np1 * p2\np1 .__ mul __（p2）\n\n\n求幂（**）\np1 ** p2\np1 .__ pow __（p2）\n\n\n相除（&#x2F;）\np1 &#x2F; p2\np1 .__ truediv __（p2）\n\n\n整除（&#x2F;&#x2F;）\np1 &#x2F;&#x2F; p2\np1 .__ floordiv __（p2）\n\n\n求模 （%）\np1％p2\np1 .__ mod __（p2）\n\n\n按位左移（&lt;&lt;）\np1 &lt;&lt; p2\np1 .__ lshift __（p2）\n\n\n按位右移（&gt;&gt;）\np1 &gt;&gt; p2\np1 .__ rshift __（p2）\n\n\n按位与（and）\np1 and p2\np1 .__ and __（p2）\n\n\n按位或（or）\np1 | 2\np1 .__ or __（p2）\n\n\n按位异或（^）\np1 ^ p2\np1 .__ xor __（p2）\n\n\n按位否（~）\n〜p1\np1 .__ invert __()\n\n\n比较运算符重载\n\n\n操作符\n表达式\n内部\n\n\n\n小于（&lt;）\np1 &lt;p2\np1 .__ lt __（p2）\n\n\n小于等于（&lt;&#x3D;）\np1 &lt;&#x3D; p2\np1 .__ le __（p2）\n\n\n等于（&#x3D;&#x3D;）\np1 &#x3D;&#x3D; p2\np1 .__ eq __（p2）\n\n\n不等于（!&#x3D;）\np1！&#x3D; p2\np1 .__ ne __（p2）\n\n\n大于（&gt;）\np1&gt; p2\np1 .__ gt __（p2）\n\n\n大于等于（&gt;&#x3D;）\np1&gt; &#x3D; p2\np1 .__ ge __（p2）\n\n\n","tags":["notes"]},{"title":"如何读论文","url":"/2024/02/16/begin/","content":"如何读论文从头开始看一篇论文所花的时间太久了，而且记忆不深，就没什么效果（对我来说），所以在参考了学长的观点后，我觉得可以从以下结构开始阅读：\n\n\n\n原来结构\n推荐结构\n\n\n\nAbstract\nAbstract(摘要)\n\n\nIntroduction\nDiscussion（讨论）\n\n\nMethods\nIntroduction（导言）\n\n\nResults\nResults（结果）\n\n\nDiscussion\nMethods（方法）\n\n\nAbstract(摘要)关注四个信息：\n\n研究目的（为什么要研究）\n方法（如何研究）\n结果（发现了什么）\n结论（它意味着什么）\n\nDiscussion（讨论）内容一般是：\n\n明确回答introduction中提出的问题\n解释结果如何支持结论\n\n看看自己是否理解和相信作者的观点\nIntroduction（导言）作用：\n\n激发我们对主题的兴趣\n将文章置于大背景中\n\n一般来说，先引导作者从一般问题（对主题的已知了解）到具体问题（对主题的未知了解），再到重点问题（作者提出的问题）。所以要介绍之前的作品以及这些作品与该主题的关系。\n想想作者为什么要做这个研究，研究的问题和讨论的问题是否一致\nResults（结果）内容一般是：\n\n作者的发现\n关键数据，通常用图表显示\n\n问问自己所收集的数据是否适合回答所研究的问题\nMethods（方法）\n做了哪些实验来回答引言中提出的问题\n\n如何找到文章的要点主要地方包括：\n\n文章标题\n\nAbstract\n\nKeywords\n\n“We hypothesize that…”（假设）\n“We propose…”(建议)\n“We introduce…”（提出）\n\n\n图表的标题\n\nintroduction的第一句和最后一句\n\n\nnotes做笔记也是阅读文献中比较重要的一步，用固定的格式比较方便查找：\n\nArticle title（文章标题）\n作者，期刊\n有关方向\n阅读日期\n网址\n主要概念（推荐结构）\n我自己的想法\n\n","tags":["论文阅读"]},{"title":"git简单使用","url":"/2025/02/22/git%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","content":"记录一下常用的命令，每次要用的时候都忘记\n初始化\ngit init\n\n存到本地\ngit clone &lt; url&gt;\n\n然后cd进入拉取的文件夹中\n设置分支\ngit branch -M main\n\n连接远程仓库\ngit remote add origin &lt;url&gt;\n\n查看是否连接成功\ngit remote -v\n\n然后可以在本地进行更改文件\n如果是共创的，更改文件前先拉取\ngit pull\n\n上传流程git add .git commit -m &quot;备注&quot;git push -u origin main(如果和前面设置的分支一致可以直接git push)\n\n上传大文件遇到需要上传100MB以上大小的文件，就需要用到Git LFS\n先下载客户端，然后打开Git Bash，进入需要上传大文件的位置cd进去\n初始化\ngit init\n\n安装git lfs\ngit lfs install\n\n将需要上传的大文件放进文件夹中，跟踪一下文件或指定文件类型（以model.h5为例）\ngit lfs track &quot;*.h5&quot; 或者 git lfs track &quot;model.h5&quot;\n\n添加.gitattributes（配置文件，缺少它执行其他git操作可能会有问题）\ngit add .gitattributes\n\n后续就是正常的上传，上传前最好先pull\n\n有坑哇，LFS超出额度需要收费，而且上传到缓存区然后删除真的很麻烦，非必要请不要使用！\n","tags":["tools"]},{"title":"实时语义分割","url":"/2025/02/20/%E5%AE%9E%E6%97%B6%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/","content":"看了一篇24年的综述，所以整理了一下\n链接：http://cjig.cn/zh/article/doi/10.11834/jig.230659/\n代码：https://github.com/xzz777/Awesome-Real-time-Semantic-Segmentation\n\n传统图像分割\n包括多种基于区域和基于边界的算法\nOTSU法、K均值聚类、分水岭、区域生长法、活动轮廓、图割法、条件随机场、马尔代夫随机场等。\n\n提出深度学习之后提出了\n全卷积网络FCN\n卷积神经网络CNN\n–&gt;需要恢复下采样损失的信息\n–&gt;多尺度的特征信息、长距离的上下文（提升精度显著）\n–&gt;丰富上下文信息的方法：扩大感受野、多尺度融合、自注意力机制\n\n更好的特征提取网络\n\nVGG(2015)\nGoogLeNet(2015)\nResNet(2016)\nHRNet(2019)\n\n更好的上下文捕获方法\n\nU-Net(2015)\nPSPNet(2017)\nRefineNet(2017)\n\n添加注意力模块的CNN\n\n\nTransformer被提出之后引入cv领域\nSETR(2021)  首次将视觉transformer应用到图像分割\nPVT(2021)  将常用的特征金字塔架构引入基于transformer图像分割的模型\nSegFormer(2021) 提出一个简洁、高效且多尺度的TransFormer图像分割模型\nSwin Transformer(2021) 可代替CNN\n–&gt;精度显著提升，但是带来了高额的计算代价；尤其是自注意力机制和自注意力机制为核心的transformer网络，虽然有全局建模能力，被证实非常适合捕获长距离上下文，但是与图像分辨率呈平方复杂度，显著增大了语义分割模型的推理延迟\n一般而言，实时语义分割网络是指在指定设备上，推理时的帧率能够达到30帧&#x2F;s及以上（即人眼对视频流畅的最低帧率要求）的语义分割网络。\n\n挑战：\n为了得到更高的分割精度，语义分割模型同时需要丰富的空间细节信息和多尺度上下文信息。然而，一方面，丰富的空间细节信息需要保留高分辨率的底层特征图，这会极大地增加计算代价；另一方面，多尺度上下文的捕获和融合又需要设计复杂的模块和交互，这会增加推理的延迟。如何以更少的计算代价，保留更丰富的空间信息、捕获更有效的多尺度上下文，以得到更好的模型速度—精度平衡，是实时分割领域一直以来的挑战和领域内研究者们一直以来的追求。此外，在一些资源受限的移动设备和边缘设备上，模型的大小和内存占用量也显得至关重要，在这些设备上的实时语义分割网络如何进行优化设计也是实时分割领域面临的一项挑战。\n\n\n单分支网络\n\n\n（1）解码器利用编码器最后的输出进行特征回复和解码（代表：ENet）\n（2）利用多尺度特征进行简单拼接融合（代表：SegFormer和SegNext）\n（3）舍弃解码器，直接对编码器特征进行分类输出\nENet：在前两个模块进行下采样，使用更小的特征图进行后续操作。\n认为解码器的作用是对编码器的输出进行上采样，只对细节进行微调，编码器本身应具有信息处理和过滤的作用。\n优点：推理速度显著提升\n缺点：精度较低\n\n\n实时语义分割研究方案主要分为三类：\n１）设计轻量化模块结构，如DUpsampling模块、ERF-PSPNet采用的残差分解卷积模块等；\n２）设计新型网络设计范式，如ICNet 和 BiSeNet采用的多支路进行信息补充的结构、将超分辨率算法引入指导低分辨率图像语义分割的方式、利用知识蒸馏指导实时语义分割网络的训练等；\n３）采用轻量级基础网络提取低级特征信息，如SwiftNet和DFANet等。\n"},{"title":"操作系统笔记","url":"/2024/10/20/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","content":"想认真学习一下，以下是看jyy老师的操作系统的笔记：\n01-操作系统概述首先要思考为什么要学“任何东西”，这个思维很开阔，很有启发\n\n由此可以思考为什么要学操作系统\n\n操作系统是如何变的？\n\n三个重要的线索：硬件（计算机）、软件（程序）、操作系统（管理硬件和软件的软件）\n操作系统是管理软硬件资源、为程序提供服务的程序。\n\n从历史时间线看操作系统的变化1946年\n\n把机械波放水银里，1振动，0不振动\n\n那个时候没有操作系统，也没有编程语言，直接写指令操作硬件。\n1950s-1960s\n\n\nCTSS\n\n操作系统出现了各类对象：设备、文件、任务……\n\n1960s-1970s\n\n\n资源隔离开来，就有了进程管理\n1970s+\n02-应用视角的操作系统编译hello world过程很复杂\n\n\n\n操作系统在应用视角来说，可以说是syscall的API\n\n\ngdb说明c语言也是一个状态机\n\n好吧，又没时间看了\n","tags":["notes"]},{"title":"UPDP","url":"/2024/07/01/%E5%89%AA%E6%9E%9D/","content":"UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer简要介绍：一种很厉害的剪枝方法，适用于cnn和transformer\n传统剪枝（pruning）模型剪枝算是模型压缩的一种，直接减少参数量，为了减少对硬件的要求、加速模型推理和落地。（模型稀疏化）\n做法：直接删除部分不重要的权重参数，减少参数量和计算量，尽量使精度不受影响。\n在神经网络中，非结构化稀疏包括权重稀疏、激活稀疏、梯度稀疏\n权重稀疏权重的数值分布比较像正态分布，而且越接近0，权重越多。\n\n卷积层的剪枝敏感性大于全连接层，且第一层卷积层最为敏感。\n剪枝三段式工作 pipeline ：训练、剪枝、微调\n\n对硬件加速不友好，尤其是GPU，因为稀疏后得到的矩阵是高度非规则的矩阵。\n激活稀疏\nAPoZ高  –&gt;  冗余\n\n剪枝三段式工作：\n\n正常训练，然后在大型数据集上运行网络以获得每个神经元的APoZ。\n根据标准修剪高APoZ的神经元，并移除相应的神经元连接。\n使用修建前的权重初始化之后再重新训练一遍。\n\n结构化稀疏（粗粒系稀疏、块稀疏）\nchannel/filter-wise 减少网络通道\nshape-wise\n\n一般都是丢弃整行或整列的权重，或者卷积层中的整个滤波器。\n结构化剪枝包含通道剪枝和块剪枝等技术。通道修剪侧重于消除内核内的整个通道过滤器，而块修剪则在更大范围内进行，通常针对完整块。\n摘要提出一种新颖的子网块修剪策略和渐进式训练方法，而且扩展到transformer模型，效果很好\n介绍主要贡献：\n（1）我们提出了一种统一且高效的深度剪枝方法来优化 CNN 和视觉 Transformer 模型。\n (2)我们提出了一种用于子网优化的渐进式训练策略，以及一种使用重新参数化技术的新颖的块修剪策略。 \n(3) 对 CNN 和视觉 Transformer 模型进行全面的实验，以展示我们的深度剪枝方法的优越剪枝性能。\n深度卷积减少计算量和参数，但是内存占用增加\n相关工作（未完待续）\n","tags":["论文阅读"]},{"title":"deep Learning知识点","url":"/2024/04/24/%E7%BB%86%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9/","content":"关于监督学习、无监督学习、半监督学习、强化学习、自监督学习的区别监督学习（Supervised Learning 或Supervised Machine Learning）使用标记数据集来训练算法，一边训练后的算法可以对数据进行分类或准确预测结果。\n可分成两类：分类（线性分类器、支持向量机、决策树、随机森林等）、回归（使用一种算法理解因变量和自变量之间的关系，有助于根据不同的数据点来预测数值）\n无监督学习（Unsupervised Learning）用算法来分析并聚类未标记的数据集，以便发现数据中隐藏的模式和规律，而不需要人工干预。\n主要用于三个任务：聚类、关联和降维\n\n聚类（Clustering）：数据挖掘技术，用于根据未标记数据的相似性或差异性对他们进行分类分组。适用于细分市场的划分、图像压缩等。\n关联（Association）：使用不同的规则来查找给定数据集中变量之间的关系。常用于推荐算法。\n降维（Dimensionality Reduction）:当特定数据集中的特征（或维度）太多时，在保持数据完整性的同时，将数据输入的数量（维度）减少到可管理可操作的大小。常用于数据预处理阶段，例如用自编码器把图片数据中的噪点去除，以提高图像质量。\n\n对比：监督学习和无监督学习本质区别就是用来训练的数据是否进行标注。\n监督学习处理数据比较耗费算力，但结果比较准确，可以解释。无监督学习处理数据算力开销不大，但是无法解释，也许是可以挖掘出未被人类注意的新规律的。\n半监督学习（Semi-supervised Learning）适用情况：相对较少的标记数据+大量未标记数据\n\n强化学习（Reinforcement Learning）对算法执行的正确和不正确行为分别进行奖励和惩罚的制度，目的是使算法获得最大的累积奖励，从而学会在特定环境下做出最佳决策。\n\n代理人，Agent：一个我们试图学习的实体（即玩家在游戏中所使用的角色）；\n环境，Environment：代理人所处的环境（游戏所设置的游戏世界设定）；\n状态，State：代理人在环境中获得自己当前状态的各种信息；\n行动，Actions：代理人在环境中所执行的与环境交互的各种动作（马里奥游戏中的行走、跑步、跳跃等等）；\n奖励，Reward：代理人从环境中获得的行动反馈（在马里奥的游戏里，即为正确的行动增加的积分&#x2F;硬币，是一个积极的奖励。因落入陷阱或被怪物吃掉而丢失积分，或损失一条“命”，则是一个消极的奖励）；\n策略，Policy：根据代理人当前的状态决定一个合适的决策，以最大化地在未来某个时间段内获得正面报酬，最小化获得负面的惩罚；\n价值函数， Value function：决定什么才是对代理人是有益的。\n\n自监督学习（self-supervised learning）SSL不需要人工标注训练数据，主要训练从大规模的无监督数据中挖掘能够应用于自身的监督信息，从而从输入的一部分数据中去学习另一部分。\n自监督学习可以通过对图片的剪裁、九宫格切割后再打乱、镜像或降低色彩饱和度等操作，让机器学会改变后的图像与原图像之间存在着十分接近的联系，这种紧密联系在二维的 Embedding 坐标空间中显示为极度靠近的坐标点。不仅仅是图片，自监督学习可以对音频、视频、文本进行同样的学习。然而这些紧密的联系，是无法通过人类标注员来操作的。就好比我们可以对图中的鸟标注为“鸟”，但是自监督学习只会把它标注为 Embedding 空间中数据结构位置信息，这在本质上和人类给这幅图标注为“鸟”是一个意思。\n可以看出，自监督学习很容易被误解为无监督学习中的聚类，因为他们也同样是把不同的未标记的事物进行分类，但其实自监督学习是在最大化同一类样本在 Embedding 空间中表征的相似性，同时最小化不同类样本之间表征的相似性。要做到相同类别的事物表达相近，不同类别的事物表达要更远，也就是说要极端化这种对比。通过这样的极端化过程，编码器（Encoder）能学到样本在 Embedding 空间中的许多潜在特征。所谓物以类聚，人以群分！\n可以对巨量数据自动进行更广泛的标注，对下游任务产生帮助。也适合挖掘大量的数据集中不被人类关注过的“隐蔽”信息。\n\n分布式训练由于硬件资源的限制，使用多台机器共同完成训练任务。\n(以下是突然找到了好早之前的笔记)\n解耦设计将不同部分分离开来，以提高灵活性、可维护性和性能。\n这种方式减少了不同部分之间的依赖关系，使他们可以更加独立地设计、实现和维护。\nDropout作用：有效的缓解过拟合现象\n在batch中，忽略一半的特征检测器（让一半的隐层节点值为0）。这种方式减少了特征检测器（隐层节点）之间的相互作用\n在前向传播的时候让某个神经元的激活值以一定的概率p停止工作，这样可以使模型的泛化性更强，因为它不会太依赖某些局部的特征\n\ndropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征\n","tags":["notes"]},{"title":"进程调度算法","url":"/2024/08/28/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/","content":"先来先服务调度算法FCFS每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。\n对短作业不利。\n适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。\n最短作业优先调度算法SJF优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。\n对长作业不利，被推迟到很后面。\n高响应比优先调度算法HRRN进程调度先运行响应比优先级最高的。$$优先权&#x3D; \\frac { 等待时间+要求服务时间 }{ 要求服务时间 }$$兼顾长作业和短作业。\n时间片轮转调度算法RR使用最广\n\n每个进程被分配一个时间段，称为时间片，即在该时间内可以为该进程运行。\n\n如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；\n如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；\n\n另外，时间片的长度就是一个很关键的点：\n\n如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；\n如果设得太长又可能引起对短作业进程的响应时间变长。将\n\n通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。\n","tags":["操作系统"]},{"title":"OCR_study","url":"/2025/04/12/OCR-study/","content":"学习书籍：《深度实践OCR:基于深度学习的文字识别》\nOCR是什么？文字识别（OCR，Optical Character Recognition）是视觉感知中的一个重要技术，目的是从照片中提取文字信息。\n发展史模式匹配（可以识别1k个印刷体汉字）-&gt;基于K-L数字变换的匹配（可以识别2k个印刷体汉字，但是造价昂贵）-&gt;LeNet5网络使OCR达到了商用的水平-&gt;AlexNet网络使cv技术进入爆发期，识别和检测间接促进了OCR技术的发展\n发展阶段传统OCR技术方法 and 基于深度学习的OCR技术方法\n有关的专用名词：\nDAR（Document Analysis and Recogition，文档图像分析和识别）\nSTR（Scene Text Recognition，场景文字识别），是OCR的重要分支。\n传统OCR方法一般流程序列化标注问题，主要目标是寻找文本串图像到文本串内容的映射，一般分解流程如下图所示：（合乎人类视觉处理逻辑）\n\nstep 1 图像输入： 对于不同的图像来说，因为有着不同的格式和压缩方式，所以需要使用不同的方法进行解码；\nstep 2 图像预处理： 主要包括二值化、去噪声、倾斜矫正等；\nstep 3 版面分析： 对文档图片分段落、分行的过程，称为版面分析；（没有固定统一的切割模型）\nstep 4 字符切割： 因为需要对每个字做识别，所以需要将版式的文字切割成一个个单字，以便用于后续的识别分类器的使用；\nstep 5 字符识别： 由早期的模板匹配，到后期的特征提取；\nstep 6 版面恢复： 根据识别后的文字，回归到原始的文档图片那样显示，段落、位置和顺序都不变的输出到 Word 文档和 PDF 文档等；\nstep 7 后处理： 根据语言模型，对识别的结果进行语义校正。\n涉及到的问题：\n处理流程的工序太多，而且是串行的，这使得错误会被不断放大\n涉及太多的人工设计，不一定能抓住问题的本质\n\n深度学习的自适应学习驱动方式可以很好地应对这些问题：\n\n文字检测手动提取特征\n\n（感觉理论又臭又长，实际上会神经网络的基础基本就能看懂，等以后有空再写吧）\n","tags":["notes"]},{"title":"Vue_study","url":"/2025/05/10/Vue-study/","content":"学习网站链接：https://www.dengruicode.com/study?uuid=58893cef7e824a02b16039129d59713c\n学习视频链接： https://www.bilibili.com/video/BV1nV411Q7RX/?p=17&amp;share_source=copy_web&amp;vd_source=44c05cee32b4f493b7fbef94d2c257f7\nVue入门以下代码涉及（可以搜索查询）：\n自动侦听器 watchEffect\n侦听器watch\n计算属性 computed\n渲染数据v-text和v-html\nv_model修饰符\n双向数据绑定v-model(v-model等于v-on+v-bind)\n遍历数组或对象v-for\n动态属性绑定v-bind\n显示与隐藏v-show\n条件渲染v-if\n绑定事件v-on和按键修饰符\nref和reactive的区别\n相关代码：\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;!-- &lt;script src=&quot;vue.global.js&quot;&gt;&lt;/script&gt; 传统开发模式--&gt;       &lt;style&gt;        .textColor&#123;            color: rgb(234, 134, 202);        &#125;     &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;app&quot;&gt;                  &lt;!-- 自动侦听器 watchEffect --&gt;         &lt;!-- 使用时要先在库导入watchEffect方法 --&gt;        &lt;!-- 侦听器watch,手动监听 --&gt;         &lt;!-- 使用时要先在库导入watch方法，需要更加精细的值时可使用 --&gt;        &lt;!-- 侦听需要在网页按F12查看终端输出 --&gt;        爱好        &lt;select v-model=&quot;hobby&quot;&gt;            &lt;option value=&quot;&quot;&gt;请选择&lt;/option&gt;            &lt;option value=&quot;A&quot;&gt;写作&lt;/option&gt;            &lt;option value=&quot;B&quot;&gt;画画&lt;/option&gt;            &lt;option value=&quot;C&quot;&gt;运动&lt;/option&gt;        &lt;/select&gt;        &lt;hr&gt;            年        &lt;select v-model=&quot;date.year&quot;&gt;            &lt;option value=&quot;&quot;&gt;请选择&lt;/option&gt;            &lt;option value=&quot;2023&quot;&gt;2023&lt;/option&gt;            &lt;option value=&quot;2024&quot;&gt;2024&lt;/option&gt;            &lt;option value=&quot;2025&quot;&gt;2025&lt;/option&gt;        &lt;/select&gt;        &lt;hr&gt;        月        &lt;select v-model=&quot;date.month&quot;&gt;            &lt;option value=&quot;&quot;&gt;请选择&lt;/option&gt;            &lt;option value=&quot;10&quot;&gt;10&lt;/option&gt;            &lt;option value=&quot;11&quot;&gt;11&lt;/option&gt;            &lt;option value=&quot;12&quot;&gt;12&lt;/option&gt;        &lt;/select&gt;        &lt;!-- 计算属性 computed --&gt;         &lt;!-- 使用时要先在库导入computed方法，在js部分创建好addnumber和subnumber --&gt;        &lt;h3&gt;add :&#123;&#123;addnumber()&#125;&#125;&lt;/h3&gt;        &lt;h3&gt;add :&#123;&#123;addnumber()&#125;&#125;&lt;/h3&gt;        &lt;h3&gt;sub :&#123;&#123;subnumber&#125;&#125;&lt;/h3&gt;        &lt;h3&gt;sub :&#123;&#123;subnumber&#125;&#125;&lt;/h3&gt;        &lt;!-- 使用v-model.number确保输入的为数字 --&gt;        x &lt;input type=&quot;text&quot; v-model.number=&quot;data.x&quot;&gt;&lt;br&gt;        y &lt;input type=&quot;text&quot; v-model.number=&quot;data.y&quot;&gt;&lt;br&gt;                  &lt;!-- 渲染数据v-text和v-html --&gt;         &lt;h3&gt;&#123;&#123;web.title&#125;&#125;&lt;/h3&gt;         &lt;!-- 将数据解析为纯文本格式 --&gt;        &lt;h3 v-text=&quot;web.title&quot;&gt;&lt;/h3&gt;        &lt;!-- 将数据解析为html格式，可以显示出颜色 --&gt;        &lt;h3 v-html=&quot;web.url&quot;&gt;&lt;/h3&gt;            &lt;!-- v_model修饰符 --&gt;        &lt;h3&gt;url: &#123;&#123; web.url &#125;&#125;&lt;/h3&gt;        &lt;h3&gt;user: &#123;&#123; web.user &#125;&#125;&lt;/h3&gt;        v-model实时渲染 &lt;input type=&quot;text&quot; v-model=&quot;web.url&quot;&gt;&lt;br&gt;        v-model.lazy失去焦点或按下回车才渲染 &lt;input type=&quot;text&quot; v-model.lazy=&quot;web.url&quot;&gt;&lt;br&gt;        &lt;!-- 输入100人，web.user的值仍为100；但是输入人数100会变成人数100，此时解析成字符串，所以v-model.number不会去解析 --&gt;        输入框的值转换成数字类型 &lt;input type=&quot;text&quot; v-model.number=&quot;web.user&quot;&gt;&lt;br&gt;        &lt;!-- 首尾的空格都可以去除，中间的不行 --&gt;        v-model.trim去除首尾空格 &lt;input type=&quot;text&quot; v-model.trim=&quot;web.url&quot;&gt;        &lt;!-- 双向数据绑定v-model --&gt;        &lt;h3&gt;文本框 &#123;&#123; data.text &#125;&#125;&lt;/h3&gt;        &lt;h3&gt;单选框 &#123;&#123; data.radio &#125;&#125;&lt;/h3&gt;        &lt;h3&gt;复选框 &#123;&#123; data.checkbox &#125;&#125;&lt;/h3&gt;        &lt;h3&gt;记住密码 &#123;&#123; data.remember &#125;&#125;&lt;/h3&gt;        &lt;h3&gt;下拉框 &#123;&#123; data.select &#125;&#125;&lt;/h3&gt;        &lt;!-- 文本框 --&gt;        &lt;!-- 单向数据绑定  当数据发生变化时，视图会自动更新，但如果用户手动更改input的值，数据不会更新 --&gt;        单向数据绑定 &lt;input type=&quot;text&quot; :value=&quot;data.text&quot;&gt;&lt;br&gt;        &lt;!-- 双向数据绑定  当数据发生变化时，视图会自动更新，用户手动更改input的值，数据也会更新             对于&lt;input type:&quot;text&quot;&gt;,v-model 绑定的时input元素的value属性 --&gt;        双向数据绑定 &lt;input type=&quot;text&quot; v-model=&quot;data.text&quot;&gt;&lt;br&gt;        &lt;!-- 单选框 对于&lt;input type=&quot;radio&quot;&gt;，v-model绑定的是input元素的选中状态--&gt;        单选框 &lt;input type=&quot;radio&quot; value=&quot;男&quot; v-model=&quot;data.radio&quot;&gt;男        &lt;input type=&quot;radio&quot; value=&quot;女&quot; v-model=&quot;data.radio&quot;&gt;女&lt;br&gt;        &lt;hr&gt;        &lt;!--             复选框            对于 &lt;input type=&quot;checkbox&quot;&gt;, v-model 绑定的是 input 元素的选中状态        --&gt;        &lt;input type=&quot;checkbox&quot; v-model=&quot;data.checkbox&quot; value=&quot;a&quot;&gt;写作        &lt;input type=&quot;checkbox&quot; v-model=&quot;data.checkbox&quot; value=&quot;b&quot;&gt;画画        &lt;input type=&quot;checkbox&quot; v-model=&quot;data.checkbox&quot; value=&quot;c&quot;&gt;运动        &lt;hr&gt;        &lt;!-- 记住密码 --&gt;        &lt;input type=&quot;checkbox&quot; v-model=&quot;data.remember&quot;&gt;记住密码        &lt;hr&gt;        &lt;!--             下拉框            对于 &lt;select&gt;, v-model 绑定的是 select 元素的选中状态        --&gt;        &lt;select v-model=&quot;data.select&quot;&gt;            &lt;option value=&quot;&quot;&gt;请选择&lt;/option&gt;            &lt;option value=&quot;A&quot;&gt;写作&lt;/option&gt;            &lt;option value=&quot;B&quot;&gt;画画&lt;/option&gt;            &lt;option value=&quot;C&quot;&gt;运动&lt;/option&gt;        &lt;/select&gt;        &lt;!-- 遍历数组或对象v-for --&gt;        &lt;ul&gt;            &lt;!-- 遍历data.number数组 --&gt;            &lt;li v-for=&quot;value in data.number&quot;&gt;                &#123;&#123;value&#125;&#125;            &lt;/li&gt;        &lt;/ul&gt;        &lt;ul&gt;            &lt;!-- 多个遍历data.number数组 --&gt;            &lt;li v-for=&quot;(value,index) in data.number&quot;&gt;                value =&gt; &#123;&#123;value&#125;&#125; : index =&gt; &#123;&#123;index&#125;&#125;            &lt;/li&gt;        &lt;/ul&gt;        &lt;ul&gt;            &lt;!-- 多个遍历data.user数组 --&gt;            &lt;li v-for=&quot;(value,key,index) in data.user&quot;&gt;                value =&gt; &#123;&#123;value&#125;&#125; : key =&gt; &#123;&#123;key&#125;&#125;: index =&gt; &#123;&#123;index&#125;&#125;            &lt;/li&gt;        &lt;/ul&gt;        &lt;ul&gt;            &lt;!-- 多个遍历data.user数组 --&gt;            &lt;template v-for=&quot;(value,key,index) in data.user&quot;&gt;                &lt;li v-if=&quot;index == 1&quot;&gt;                    value =&gt; &#123;&#123;value&#125;&#125; : key =&gt; &#123;&#123;key&#125;&#125;: index =&gt; &#123;&#123;index&#125;&#125;                &lt;/li&gt;                &lt;/template&gt;        &lt;/ul&gt;        &lt;!-- Vue会编译&lt;template&gt;的内容，但是不会将其作为DOM元素渲染到页面上 --&gt;        &lt;ul&gt;            &lt;!-- 多个遍历data.teacher数组,两个对象的数组 :key作用 ：无论列表如何变化，输入框的状态都会与对应数据项正确绑定。--&gt;            &lt;li v-for=&quot;(value,index) in data.teacher&quot; :title=&quot;value.name&quot; :key=&quot;value.id&quot;&gt;                 index =&gt; &#123;&#123;index&#125;&#125;:value.id =&gt; &#123;&#123;value.id&#125;&#125; :value.name =&gt; &#123;&#123;value.name&#125;&#125;             &lt;/li&gt;        &lt;/ul&gt;        &lt;!-- 动态属性绑定v-bind --&gt;        &lt;!-- ：value --&gt;        &lt;h3&gt;value=&quot;哈哈哈&quot;&lt;/h3&gt;        &lt;input type=&quot;text&quot; value=&quot;哈哈&quot;&gt;        &lt;!-- 将value改成动态属性 --&gt;        &lt;h3&gt;v-bind:value=&quot;web.URL&quot;&lt;/h3&gt;        &lt;input type=&quot;text&quot; v-bind:value=&quot;web.URL&quot;&gt;        &lt;!-- 简写 --&gt;        &lt;h3&gt;:value=&quot;web.URL&quot;&lt;/h3&gt;        &lt;input type=&quot;text&quot; :value=&quot;web.URL&quot;&gt;        &lt;!-- :src --&gt;        &lt;h3&gt;src=&quot;zwz_image.jpg&quot;&lt;/h3&gt;        &lt;img   src=&quot;zwz_image.jpg&quot; &gt;        &lt;!-- src的动态属性绑定 --&gt;        &lt;h3&gt;:src=&quot;web.img&quot;&lt;/h3&gt;        &lt;img  : src=&quot;web.img&quot; &gt;        &lt;!-- :class --&gt;        &lt;h3&gt;class=&quot;textColor&quot;&lt;/h3&gt;        &lt;b class=&quot;textColor&quot;&gt;你好，我是曾丸子&lt;/b&gt;        &lt;!-- class的动态属性绑定 --&gt;         &lt;h3&gt;:class=&quot;&#123;textColor:web.fontStatus&#125;&quot;&lt;/h3&gt;        &lt;b :class=&quot;&#123;textColor:web.fontStatus&#125;&quot;&gt;你好，我是曾丸子&lt;/b&gt;        &lt;h3&gt;:class=&quot;web.fontStatus ? &#x27;textColor&#x27; : &#x27;&#x27;&quot;&lt;/h3&gt;        &#123;&#123; message &#125;&#125;        &#123;&#123;web.show&#125;&#125;&lt;hr&gt;        &lt;!-- 显示与隐藏v-show --&gt;        &lt;p v-show=&quot;web.show&quot;&gt;你好，我是曾丸子&lt;/p&gt;         &lt;!-- 可以使用web.show控制显示与隐藏 --&gt;        &lt;p v-if=&quot;web.show&quot;&gt;你好，我不是曾丸子&lt;/p&gt;        &lt;!-- v-if:当条件为true就渲染，条件为false时就不渲染，不适合频繁点击，性能会下降 --&gt;        &lt;!-- 条件渲染v-if,if-else的应用 --&gt;         &lt;p v-if=&quot;web.user &lt;1000&quot;&gt;新一年&lt;/p&gt;         &lt;p v-else-if=&quot;web.user &gt;=1000 &amp;&amp; web.user &lt;10000&quot;&gt;优秀的一年&lt;/p&gt;         &lt;p v-else&gt;牛逼的一年&lt;/p&gt;        &lt;h2&gt;&#123;&#123;web.title&#125;&#125;&lt;/h2&gt;        &lt;h2&gt;&#123;&#123;web.URL&#125;&#125;&lt;/h2&gt;        &lt;h2&gt;&#123;&#123;number&#125;&#125;&lt;/h2&gt;        &lt;button @click=&quot;toggle&quot;&gt;切换显示状态&lt;/button&gt;        &lt;!-- 绑定事件v-on和按键修饰符 --&gt;        &lt;!-- 设置一个按钮，为事件绑定edit(v:on和@作用是一样的) --&gt;        &lt;button v-on:click=&quot;edit&quot;&gt;修改&lt;/button&gt;&lt;br&gt;        &lt;button @click=&quot;edit&quot;&gt;修改@&lt;/button&gt;&lt;hr&gt;        &lt;!-- 改变状态的按键和框 --&gt;        回车 &lt;input type=&quot;text&quot; @keyup.enter=&quot;add(40,60)&quot;&gt;&lt;br&gt;        空格 &lt;input type=&quot;text&quot; @keyup.space=&quot;add(20,30)&quot;&gt;&lt;br&gt;        Tab &lt;input type=&quot;text&quot; @keydown.tab=&quot;add(10,20)&quot;&gt;&lt;br&gt;        w &lt;input type=&quot;text&quot; @keyup.w=&quot;add(5,10)&quot;&gt;&lt;br&gt;        Ctrl+Enter &lt;input type=&quot;text&quot; @keyup.ctrl.enter=&quot;add(1,2)&quot;&gt;&lt;br&gt;        &lt;!-- 组合按键 --&gt;        &lt;!-- 设置一个按钮，为事件绑定add(keyup是松开按键，enter是回车) --&gt;    &lt;/div&gt;    &lt;script type=&quot;module&quot;&gt;        import &#123; createApp,reactive,ref,computed,watch,watchEffect &#125; from &#x27;./vue.esm-browser.js&#x27; //模块化开发模式        //解构赋值，将Vue属性赋值给变量        // Vue是一个对象，包含了Vue的所有属性和方法        // const&#123;createApp, reactive&#125; = Vue        // ref和reactive的区别        const number =ref(10) //ref()用于存储简单数据类型，如：数字、字符串、布尔值、数组等。使用ref创建的变量需要通过.value来访问和修改值        number.value = 20 //修改值        // Vue.createApp()  创建一个Vue应用        // mount()  挂载到页面上                    createApp(&#123;            // setup选项  用于设置响应式数据和方法等            setup() &#123;                const hobby = ref(&quot;&quot;) //爱好                const date = reactive(&#123; //reactive()用于存储复杂数据类型，如：对象或数组等。使用reactive创建可以直接通过属性名来访问和修改值                    year: 2023,                    month: 10                &#125;)                //自动侦听器 watchEffect                watchEffect(() =&gt; &#123; //自动侦听器watchEffect                    console.log(&quot;------监听开始&quot;);                    console.log(&quot;hobby&quot;, hobby.value) //打印                    console.log(&quot;date&quot;, date.year, date.month) //打印                    console.log(&quot;------监听结束&quot;)                    /*                        watchEffect() 是 Vue 3 中的一个 API，用于创建一个响应式的副作用函数。                        它会自动追踪函数中使用的响应式数据，并在这些数据发生变化时重新执行函数。                        watchEffect() 不需要手动指定要侦听的数据，它会自动侦听函数中使用的所有响应式数据。                    */                &#125;)                //侦听器watch                watch(hobby, (newValue, oldValue) =&gt; &#123;                     console.log(&quot;hobby&quot;,&quot;newValue&quot;, newValue,&quot;oldValue&quot;, oldValue) //打印                    // 侦听器watch 侦听hobby的值变化                    // newValue:新值 oldValue:旧值                    if (newValue === &quot;A&quot;) &#123;                        console.log(&quot;写作&quot;)                    &#125; else if (newValue === &quot;B&quot;) &#123;                        console.log(&quot;画画&quot;)                    &#125; else if (newValue === &quot;C&quot;) &#123;                        console.log(&quot;运动&quot;)                    &#125;                    //侦听 date                    watch(date, (newValue, oldValue) =&gt; &#123; //侦听器watch                        console.log(&quot;date&quot;,&quot;newValue&quot;, newValue,&quot;oldValue&quot;, oldValue) //打印                        /*                            JS中对象和数组是通过引用传递的，而不是通过值传递                            当修改对象或数值时，实际上是修改了对象和数组的引用，而不是创建一个新的对象或数组                            所以，如果修改了对象或数组的值，那么打印出来的结果是修改后的结果                        */                        if (newValue.year === &quot;2023&quot;) &#123;                            console.log(&quot;2023&quot;)                        &#125; else if (newValue.year === &quot;2024&quot;) &#123;                            console.log(&quot;2024&quot;)                        &#125; else if (newValue.year === &quot;2025&quot;) &#123;                            console.log(&quot;2025&quot;)                        &#125;                        if (newValue.month === &quot;10&quot;) &#123;                            console.log(&quot;10&quot;)                        &#125; else if (newValue.month === &quot;11&quot;) &#123;                            console.log(&quot;11&quot;)                        &#125; else if (newValue.month === &quot;12&quot;) &#123;                            console.log(&quot;12&quot;)                        &#125;                    &#125;)                    //监听 date 中的某个属性 year                    watch(() =&gt; date.year, (newValue, oldValue) =&gt; &#123;                        console.log(&quot;oldValue&quot;, oldValue, &quot;newValue&quot;, newValue)                        if (date.year == &quot;2024&quot;) &#123;                            console.log(&quot;2024&quot;)                        &#125;                    &#125;)                &#125;)                const data =reactive(&#123;                    number:[&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;], //数组                    user:&#123;  //对象                        name:&quot;zwz&quot;,                        gender: &quot;女&quot;                    &#125;,                    teacher:[ //包含两个对象的数组                        &#123;id:100,name:&quot;bcy&quot;,web:&quot;bcy.com&quot;&#125;,                        &#123;id:101,name:&quot;bamboo&quot;,web:&quot;bamboo.com&quot;&#125;                    ],                    text: &quot;hello world&quot;, //文本框                    radio: &quot;&quot;,//单选框                    checkbox: [],//复选框                    remember: false,//单个复选框-记住密码                    select: &quot;&quot;,//下拉框                    x :10,                    y: 20                &#125;)                //方法 -无缓存 只要调用就会执行  调用时为addnumber()                let addnumber = () =&gt; &#123;                    console.log(&quot;addnumber&quot;) //打印                    return data.x + data.y                &#125;                //属性 -有缓存 可以提高性能，不需要重复计算，当数据发生变化时才需要重新计算  调用时为subnumber 不需要加括号，因为是属性                const subnumber = computed(() =&gt; &#123;                    console.log(&quot;subnumber&quot;) //打印                    return data.x - data.y                &#125;)                //定义一个网站                const web = reactive(&#123; //reactive()用于存储复杂数据类型，如：对象或数组等。使用reactive创建可以直接通过属性名来访问和修改值                    title: &quot;hello world&quot;,                    url: &quot;&lt;i style=&#x27;color:rgb(234, 134, 202)&#x27;&gt;bcy.com&lt;/i&gt;&quot;,                    show: true,                    user: 10,                    img: &quot;zwz_image.jpg&quot;,                    fontStatus: true                &#125;)                web.URL = &quot;bamboo.com&quot; //修改值                //获取网站新增用户数                const add = (a,b) =&gt; &#123;                    web.URL += a + b //修改值                &#125;                //修改网站的网址                const edit = () =&gt; &#123; //定义一个方法                    web.URL = 20 //修改值                &#125;                //定义可以切换show状态的函数                const toggle = () =&gt; &#123;                    web.show = !web.show //修改值                &#125;                return &#123; //实现页面的返回                    message: &#x27;success&#x27;,                    number, //number是一个ref对象，直接返回即可                    web,                    edit,                    add,                    toggle,                    data,                    addnumber,                    subnumber,                    hobby,                    date                &#125;            &#125;        &#125;).mount(&#x27;#app&#x27;)    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\nVue项目实战图片轮播功能（4张图片，命名为n.jpg，实现了图片的任意切换）&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;app&quot;&gt;        &lt;h3&gt;&#123;&#123; number &#125;&#125;&lt;/h3&gt;        &lt;!-- 显示一张图片时可以直接导入 --&gt;        &lt;!-- &lt;img   src=&quot;/images/1.jpg&quot;  style=&quot;width: 300px;&quot;&gt; --&gt;         &lt;!-- 多张照片可以使用：src动态属性绑定，然后改成字符串 --&gt;        &lt;img :src=`/images/$&#123;number&#125;.jpg` style=&quot;width: 300px;&quot;&gt; &lt;hr&gt;        &lt;button @click=&quot;prev&quot;&gt;上一张&lt;/button&gt;        &lt;button @click=&quot;next&quot;&gt;下一张&lt;/button&gt;        &lt;!-- 遍历并使用jump函数实现图片的跳转 --&gt;        &lt;ul&gt;            &lt;li v-for=&quot;(value, index) in 4&quot;&gt;                &lt;a href=&quot;#&quot; @click=&quot;jump(value)&quot;&gt;&#123;&#123; value &#125;&#125;&lt;/a&gt;            &lt;/li&gt;        &lt;/ul&gt;    &lt;/div&gt;    &lt;script type=&quot;module&quot;&gt;        import &#123; createApp, ref &#125; from &#x27;./vue.esm-browser.js&#x27;        createApp(&#123;            setup() &#123;                const number = ref(1)                //上一张                const prev = () =&gt; &#123;                    number.value--                    if (number.value == 0) &#123;                        number.value = 4                    &#125;                &#125;                //下一张                const next = () =&gt; &#123;                    number.value++                    if (number.value == 5) &#123;                        number.value = 1                    &#125;                &#125;                //跳转                const jump = (value) =&gt; &#123;                    number.value = value                &#125;                return &#123;                    number,                    prev,                    next,                    jump                &#125;            &#125;        &#125;).mount(&quot;#app&quot;)    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n记事本功能（使用list当作记事本，实现增加、删除、清空功能）&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;app&quot;&gt;        &lt;input type=&quot;text&quot; v-model = &quot;data.content&quot;&gt;        &lt;button @click=&quot;add&quot;&gt;添加&lt;/button&gt;        &lt;ul&gt;            &lt;li v-for=&quot;(value,index) in data.list&quot;&gt;                &#123;&#123;value&#125;&#125;                &lt;button @click=&quot;del(index)&quot;&gt;删除&lt;/button&gt;            &lt;/li&gt;        &lt;/ul&gt;        &lt;!-- 获取list中的数量 --&gt;         &#123;&#123;data.list.length&#125;&#125;&lt;button @click=&quot;clear&quot;&gt;清空&lt;/button&gt;    &lt;/div&gt;    &lt;script type=&quot;module&quot;&gt;        import &#123; createApp,reactive &#125; from &#x27;./vue.esm-browser.js&#x27;        createApp(&#123;            setup()&#123;                const data = reactive(&#123;                    content:&quot;hello world&quot;,                    list: [&quot;1&quot;,&quot;2&quot;]                &#125;)                //增加记录到list中                const add = () =&gt; &#123;                    data.list.push(data.content)                    console.log(data.list)                &#125;                //从list删除记录                const del = (index) =&gt; &#123;                    data.list.splice(index,1)                    console.log(data.list)                &#125;                //清空list                const clear = () =&gt; &#123;                    data.list = []                    console.log(data.list)                &#125;                return &#123;                    data,                    add,                    del,                    clear                &#125;            &#125;        &#125;).mount(&#x27;#app&#x27;)    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n购物车功能（实时监听+有缓存的计算）\n&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot;&gt;    &lt;title&gt;Title&lt;/title&gt;    &lt;style&gt;        table &#123;            width: 600px;            color: #8f8e8e;            text-align: center;            border-collapse: collapse;        &#125;        table thead &#123;            background: #F5F5F5;        &#125;        table tr &#123;            height: 30px;            line-height: 30px;            border: 1px solid #ececec;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=&quot;app&quot;&gt;        &lt;table&gt;            &lt;thead&gt;                &lt;tr&gt;                    &lt;!-- &lt;td&gt;&lt;input type=&quot;checkbox&quot; v-model=&quot;data.selected&quot; @change=&quot;selectAll&quot; /&gt;&lt;/td&gt; --&gt;                    &lt;td&gt;&lt;input type=&quot;checkbox&quot; v-model=&quot;data.selected&quot; /&gt;&lt;/td&gt;                    &lt;td&gt;商品&lt;/td&gt;                    &lt;td&gt;单价&lt;/td&gt;                    &lt;td&gt;库存&lt;/td&gt;                    &lt;td colspan=&quot;2&quot;&gt;操作&lt;/td&gt;                &lt;/tr&gt;            &lt;/thead&gt;            &lt;tbody&gt;                &lt;tr v-for=&quot;(value, index) in data.list&quot;&gt;                    &lt;!--                     &lt;td&gt;&lt;input type=&quot;checkbox&quot; v-model=&quot;data.checkboxList&quot; :value=&quot;value&quot; @change=&quot;checkSelect&quot; /&gt;&lt;/td&gt;                     --&gt;                    &lt;td&gt;&lt;input type=&quot;checkbox&quot; v-model=&quot;data.checkboxList&quot; :value=&quot;value&quot; /&gt;&lt;/td&gt;                    &lt;td&gt;&#123;&#123; value.name &#125;&#125;&lt;/td&gt;                    &lt;td&gt;&#123;&#123; value.price &#125;&#125;&lt;/td&gt;                    &lt;td&gt;&#123;&#123; value.stock &#125;&#125;&lt;/td&gt;                    &lt;td&gt;                        &lt;button @click=&quot;sub(value)&quot;&gt;-&lt;/button&gt;                        &#123;&#123; value.number &#125;&#125;                        &lt;button @click=&quot;add(value)&quot;&gt;+&lt;/button&gt;                    &lt;/td&gt;                    &lt;td&gt;&lt;button @click=&quot;del(index,value.id)&quot;&gt;删除&lt;/button&gt;&lt;/td&gt;                &lt;/tr&gt;            &lt;/tbody&gt;            &lt;tfoot&gt;                &lt;tr&gt;                    &lt;!-- &lt;td&gt;总价 &#123;&#123; totalPrice() &#125;&#125;&lt;/td&gt; --&gt;                    &lt;td&gt;总价 &#123;&#123; totalPrice &#125;&#125;&lt;/td&gt;                &lt;/tr&gt;            &lt;/tfoot&gt;        &lt;/table&gt;    &lt;/div&gt;    &lt;script type=&quot;module&quot;&gt;        import &#123; createApp, reactive, watch, computed &#125; from &#x27;./vue.esm-browser.js&#x27;        createApp(&#123;            setup() &#123;                const data = reactive(&#123;                    selected: false,                    checkboxList: [],                    list: [&#123;                        id: 1,                        name: &quot;铅笔&quot;,                        price: 10,                        number: 1,                        stock: 3                    &#125;,                    &#123;                        id: 2,                        name: &quot;鼠标&quot;,                        price: 20,                        number: 2,                        stock: 5                    &#125;,                    &#123;                        id: 3,                        name: &quot;键盘&quot;,                        price: 30,                        number: 1,                        stock: 6                    &#125;],                &#125;)                //减                const sub = (value) =&gt; &#123;                    value.number--                    if (value.number &lt;= 1) &#123;                        value.number = 1                    &#125;                &#125;                //加                const add = (value) =&gt; &#123;                    value.number++                    if (value.number &gt;= value.stock) &#123;                        value.number = value.stock                    &#125;                &#125;                //删除                //先将list中的删除，list中直接按照索引位置删，再将表示选中的数组按照id将要删除的移除数组                const del = (index, id) =&gt; &#123;                    data.list.splice(index, 1) //splice(要删除元素的索引位置, 要删除的元素数量)                    //filter 筛选符合条件的元素, 返回一个新的数组                    let newArr = data.checkboxList.filter((value, index) =&gt; &#123;                        return value.id != id                    &#125;)                    data.checkboxList = newArr                    //checkSelect() //检查勾选状态                &#125;                /*                //总价                const totalPrice = () =&gt; &#123;                    let total = 0                    for (let i = 0; i &lt; data.checkboxList.length; i++) &#123;                        total += data.checkboxList[i].price * data.checkboxList[i].number                    &#125;                    return total                &#125;                */                //计算属性-有缓存 [计算属性根据其依赖的响应式数据变化而重新计算]                const totalPrice = computed(() =&gt; &#123;                    /*                        reduce定义: 用于对数组中的所有元素进行迭代操作, 并将每次操作的结果累加到一个初始值上                        reduce接收两个参数: 一个是累加器函数, 另一个是初始值                        reduce: 将 data.checkboxList 数组中的每个 checkbox 对象的 price 和 number 属性进行相乘,                         并将结果累加到初始值 0 上, 最后返回累加的结果                        total(累加器) 用于存储每次计算的结果, 初始值为 0                        item(当前元素) 在每次迭代过程中, 当前元素的值会被传递给回调函数                    */                    return data.checkboxList.reduce((total, item) =&gt; total + item.price * item.number, 0)                &#125;)                /*                //全选/反选                const selectAll = () =&gt; &#123;                    if (data.selected) &#123; //true                        data.checkboxList = data.list                    &#125; else &#123; //false                        data.checkboxList = []                    &#125;                &#125;                */                //监听 data.selected                let flag = true                //上面监听为false，所以要另设一个标记位                //缺少不全选的判断，通过标记位将不全选状态传递给第一个watch作判断                watch(() =&gt; data.selected, (newValue, oldValue) =&gt; &#123;                    //console.log(&quot;newValue:&quot;,newValue,&quot;oldValue:&quot;,oldValue)                    if (newValue) &#123;                        data.checkboxList = data.list                    &#125; else &#123;                        if (flag) &#123;                            data.checkboxList = []                        &#125;                    &#125;                    //console.log(data.checkboxList)                &#125;)                                /*                //检查勾选状态                const checkSelect = () =&gt; &#123;                    if (data.checkboxList.length == data.list.length &amp;&amp; data.list.length != 0) &#123;                        data.selected = true                    &#125; else &#123;                        data.selected = false                    &#125;                &#125;                */                //监听 data.checkboxList                watch(() =&gt; data.checkboxList, (newValue, oldValue) =&gt; &#123;                    console.log(&quot;newValue:&quot;, newValue, &quot;oldValue:&quot;, oldValue)                    console.log(newValue.length)                    if (newValue.length == data.list.length &amp;&amp; data.list.length != 0) &#123;                        data.selected = true                        flag = true                    &#125; else &#123;                        data.selected = false                        flag = false                    &#125;                &#125;)                                return &#123;                    data,                    sub,                    add,                    del,                    totalPrice                    //selectAll,                    //checkSelect                &#125;            &#125;        &#125;).mount(&quot;#app&quot;)    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n"}]